{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a2222579-9a7b-4f27-8ec8-aec7e6efd80a",
      "metadata": {
        "id": "a2222579-9a7b-4f27-8ec8-aec7e6efd80a"
      },
      "source": [
        "## Imports and Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3b77b39f-323f-45f9-8f03-f06c2f55ad10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b77b39f-323f-45f9-8f03-f06c2f55ad10",
        "outputId": "d28f0cde-c176-4a06-b6b6-1fc0fbf7f089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers\n",
        "# ! pip3 install wandb\n",
        "# ! pip install rouge_score\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import os, gc\n",
        "import re\n",
        "\n",
        "from transformers import AutoTokenizer, LongformerTokenizer, RobertaTokenizer\n",
        "from transformers import LongformerForQuestionAnswering, AutoModelForSeq2SeqLM\n",
        "\n",
        "from torch import cuda, nn, optim\n",
        "# from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "# import rouge_score\n",
        "# import wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "25f49cd5-8dc0-4c85-bdc5-83d71e7371cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25f49cd5-8dc0-4c85-bdc5-83d71e7371cd",
        "outputId": "d75ae265-e8d6-4387-b1b5-60fdeb1fba17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "manual_seed = 595\n",
        "torch.manual_seed(manual_seed)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbc84a4d-7204-4466-95ee-9907cbba2107",
      "metadata": {
        "id": "dbc84a4d-7204-4466-95ee-9907cbba2107"
      },
      "source": [
        "## Read the Cleaned Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f48d661-5ec8-4851-b510-c9ef877d8d38",
      "metadata": {
        "id": "8f48d661-5ec8-4851-b510-c9ef877d8d38"
      },
      "source": [
        "### Define the paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "08f955f6-045d-4453-ad45-39e67216ef59",
      "metadata": {
        "id": "08f955f6-045d-4453-ad45-39e67216ef59"
      },
      "outputs": [],
      "source": [
        "# run locally\n",
        "text_path = '../formatted_cases/'\n",
        "file = '../../annotated_data.xlsx'\n",
        "REGEX = r';+'\n",
        "sup_path = '../annotated_sup/'\n",
        "multi_path = text_path + 'multiple_files/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "46377399-e3a0-4a2a-9325-d86d5f0b6939",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46377399-e3a0-4a2a-9325-d86d5f0b6939",
        "outputId": "ebaa4b2b-d510-49e2-923e-ca13da3362be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# run on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "text_path = '/content/gdrive/My Drive/595/formatted_cases/'\n",
        "file = '/content/gdrive/My Drive/595/annotated_data.xlsx'\n",
        "REGEX = r';+'\n",
        "sup_path = '/content/gdrive/My Drive/595/annotated_sup/'\n",
        "multi_path = text_path + 'multiple_files/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "kmLgbrAaYPLO",
      "metadata": {
        "id": "kmLgbrAaYPLO"
      },
      "outputs": [],
      "source": [
        "# wandb.login()\n",
        "# wandb.init(project=\"RTB_Cases\", entity=\"qmygrace\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5846c80-5bf1-4118-90d0-b7d9a2f5b4a5",
      "metadata": {
        "id": "f5846c80-5bf1-4118-90d0-b7d9a2f5b4a5"
      },
      "source": [
        "### Clean the Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b773cee8-0f30-48b5-a78b-c8482bb76e49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "b773cee8-0f30-48b5-a78b-c8482bb76e49",
        "outputId": "e2c06d39-abd4-4140-d27d-d4ee52237aa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(702, 50)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  What is the file number of the case?  \\\n",
              "0                         CEL-87788-19   \n",
              "1                         CEL-90549-19   \n",
              "2                         TEL-94478-18   \n",
              "3                         TEL-94493-18   \n",
              "4                         CEL-72994-18   \n",
              "5                         CEL-73021-18   \n",
              "\n",
              "  What was the date of the hearing? [mm/dd/yyyy]  \\\n",
              "0                            2019-10-16 00:00:00   \n",
              "1                            2020-01-22 00:00:00   \n",
              "2                            2018-10-31 00:00:00   \n",
              "3                            2018-10-31 00:00:00   \n",
              "4                            2018-03-07 00:00:00   \n",
              "5                            2018-06-15 00:00:00   \n",
              "\n",
              "  What was the date of the decision? [mm/dd/yyyy]  \\\n",
              "0                             2020-06-04 00:00:00   \n",
              "1                             2020-01-10 00:00:00   \n",
              "2                             2018-11-21 00:00:00   \n",
              "3                             2018-11-21 00:00:00   \n",
              "4                             2018-03-14 00:00:00   \n",
              "5                             2018-06-18 00:00:00   \n",
              "\n",
              "  Who was the member adjudicating the decision?  \\\n",
              "0                               Sonia Anwar-Ali   \n",
              "1                               Shelby Whittick   \n",
              "2                       Ruth Carey (Vice Chair)   \n",
              "3                      Ruth Carey (Vice Chair)    \n",
              "4                                 Avril Cardoso   \n",
              "5                                 Avril Cardoso   \n",
              "\n",
              "  What was the location of the landlord tenant board?  \\\n",
              "0                                            Toronto    \n",
              "1                                        Mississauga    \n",
              "2                                            Toronto    \n",
              "3                                            Toronto    \n",
              "4                                        Mississauga    \n",
              "5                                        Mississauga    \n",
              "\n",
              "  Did the decision state the landlord was represented?  \\\n",
              "0                                                Yes     \n",
              "1                                                Yes     \n",
              "2                                                Yes     \n",
              "3                                                Yes     \n",
              "4                                                Yes     \n",
              "5                                                Yes     \n",
              "\n",
              "  Did the decision state the landlord attended the hearing?  \\\n",
              "0                                         Not stated          \n",
              "1                                                Yes          \n",
              "2                                                Yes          \n",
              "3                                                Yes          \n",
              "4                                                 No          \n",
              "5                                                 No          \n",
              "\n",
              "  Did the decision state the tenant was represented?  \\\n",
              "0                                                 No   \n",
              "1                                                 No   \n",
              "2                                                 No   \n",
              "3                                                 No   \n",
              "4                                                Yes   \n",
              "5                                                 No   \n",
              "\n",
              "  Did the decision state the tenant attended the hearing?  \\\n",
              "0                                         Not stated        \n",
              "1                                                Yes        \n",
              "2                                                Yes        \n",
              "3                                                Yes        \n",
              "4                                                 No        \n",
              "5                                                 No        \n",
              "\n",
              "  Did the decision state the landlord was a not-for-profit landlord (e.g. Toronto Community Housing)?  \\\n",
              "0                                                 No                                                    \n",
              "1                                                 No                                                    \n",
              "2                                                 No                                                    \n",
              "3                                                 No                                                    \n",
              "4                                                 No                                                    \n",
              "5                                                 No                                                    \n",
              "\n",
              "   ...  \\\n",
              "0  ...   \n",
              "1  ...   \n",
              "2  ...   \n",
              "3  ...   \n",
              "4  ...   \n",
              "5  ...   \n",
              "\n",
              "  If the tenant did propose a payment plan, did the member accept the proposed payment plan?  \\\n",
              "0                                         Not stated                                           \n",
              "1                                                 No                                           \n",
              "2                                         Not stated                                           \n",
              "3                                                Yes                                           \n",
              "4                                                 No                                           \n",
              "5                                         Not stated                                           \n",
              "\n",
              "  If a payment plan was ordered, what was the length of the payment plan?   \\\n",
              "0                                                 12                         \n",
              "1                                         Not stated                         \n",
              "2                                         Not stated                         \n",
              "3                                                  1                         \n",
              "4                                         Not stated                         \n",
              "5                                         Not stated                         \n",
              "\n",
              "  Did the decision mention the tenant’s difficulty finding alternative housing for any reason e.g.physical limitations, reliance on social assistance, etc.?  \\\n",
              "0                                                 No                                                                                                           \n",
              "1                                                 No                                                                                                           \n",
              "2                                                 No                                                                                                           \n",
              "3                                                 No                                                                                                           \n",
              "4                                                 No                                                                                                           \n",
              "5                                                 No                                                                                                           \n",
              "\n",
              "  If the tenant had difficulty finding alternative housing for any reason, which of the following were applicable to the tenant?  \\\n",
              "0                                         Not stated                                                                               \n",
              "1                                         Not stated                                                                               \n",
              "2                                         Not stated                                                                               \n",
              "3                                         Not stated                                                                               \n",
              "4                                         Not stated                                                                               \n",
              "5                                         Not stated                                                                               \n",
              "\n",
              "  Did the decision state the tenant was given prior notice for the eviction?  \\\n",
              "0                                                 No                           \n",
              "1                                                Yes                           \n",
              "2                                                Yes                           \n",
              "3                                                Yes                           \n",
              "4                                                Yes                           \n",
              "5                                                Yes                           \n",
              "\n",
              "  If the tenant was given prior notice for the eviction, how much notice was given?  \\\n",
              "0                                         Not stated                                  \n",
              "1                                         Not stated                                  \n",
              "2                                         Not stated                                  \n",
              "3                                         Not stated                                  \n",
              "4                                         Not stated                                  \n",
              "5                                         Not stated                                  \n",
              "\n",
              "  Did the decisions state postponement would result in the tenant accruing additional arrears?  \\\n",
              "0                                                 No                                             \n",
              "1                                                Yes                                             \n",
              "2                                                 No                                             \n",
              "3                                                 No                                             \n",
              "4                                                 No                                             \n",
              "5                                                 No                                             \n",
              "\n",
              "  Which other specific applications of the landlord or the tenant were mentioned?  \\\n",
              "0  L2: Application to End a Tenancy and Evict a T...                                \n",
              "1      No other specific applications were mentioned                                \n",
              "2  N13: Notice to End your Tenancy Because the La...                                \n",
              "3      No other specific applications were mentioned                                \n",
              "4      No other specific applications were mentioned                                \n",
              "5  L1: Application to Evict a Tenant for Non-paym...                                \n",
              "\n",
              "  Did the decision mention the validity of an N4 eviction notice?  \\\n",
              "0                                                 No                \n",
              "1                                                 No                \n",
              "2                                                 No                \n",
              "3                                                 No                \n",
              "4                                                 No                \n",
              "5                                                 No                \n",
              "\n",
              "  Were there detail(s) in the decision not captured by this questionnaire that should be included?  \n",
              "0  Tenant was a single mother with no support fro...                                                \n",
              "1                                         Not stated                                                \n",
              "2  Previous decision TEL-92736-18 < This decision...                                                \n",
              "3  There were 7 previous application for non-paym...                                                \n",
              "4  Third Application by Landlord in past 6 months...                                                \n",
              "5  Tenant did not show up because hearing took pl...                                                \n",
              "\n",
              "[6 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da50660e-a91b-488c-b72b-1d6a03125832\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>What is the file number of the case?</th>\n",
              "      <th>What was the date of the hearing? [mm/dd/yyyy]</th>\n",
              "      <th>What was the date of the decision? [mm/dd/yyyy]</th>\n",
              "      <th>Who was the member adjudicating the decision?</th>\n",
              "      <th>What was the location of the landlord tenant board?</th>\n",
              "      <th>Did the decision state the landlord was represented?</th>\n",
              "      <th>Did the decision state the landlord attended the hearing?</th>\n",
              "      <th>Did the decision state the tenant was represented?</th>\n",
              "      <th>Did the decision state the tenant attended the hearing?</th>\n",
              "      <th>Did the decision state the landlord was a not-for-profit landlord (e.g. Toronto Community Housing)?</th>\n",
              "      <th>...</th>\n",
              "      <th>If the tenant did propose a payment plan, did the member accept the proposed payment plan?</th>\n",
              "      <th>If a payment plan was ordered, what was the length of the payment plan?</th>\n",
              "      <th>Did the decision mention the tenant’s difficulty finding alternative housing for any reason e.g.physical limitations, reliance on social assistance, etc.?</th>\n",
              "      <th>If the tenant had difficulty finding alternative housing for any reason, which of the following were applicable to the tenant?</th>\n",
              "      <th>Did the decision state the tenant was given prior notice for the eviction?</th>\n",
              "      <th>If the tenant was given prior notice for the eviction, how much notice was given?</th>\n",
              "      <th>Did the decisions state postponement would result in the tenant accruing additional arrears?</th>\n",
              "      <th>Which other specific applications of the landlord or the tenant were mentioned?</th>\n",
              "      <th>Did the decision mention the validity of an N4 eviction notice?</th>\n",
              "      <th>Were there detail(s) in the decision not captured by this questionnaire that should be included?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CEL-87788-19</td>\n",
              "      <td>2019-10-16 00:00:00</td>\n",
              "      <td>2020-06-04 00:00:00</td>\n",
              "      <td>Sonia Anwar-Ali</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>12</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>L2: Application to End a Tenancy and Evict a T...</td>\n",
              "      <td>No</td>\n",
              "      <td>Tenant was a single mother with no support fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CEL-90549-19</td>\n",
              "      <td>2020-01-22 00:00:00</td>\n",
              "      <td>2020-01-10 00:00:00</td>\n",
              "      <td>Shelby Whittick</td>\n",
              "      <td>Mississauga</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No other specific applications were mentioned</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEL-94478-18</td>\n",
              "      <td>2018-10-31 00:00:00</td>\n",
              "      <td>2018-11-21 00:00:00</td>\n",
              "      <td>Ruth Carey (Vice Chair)</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>N13: Notice to End your Tenancy Because the La...</td>\n",
              "      <td>No</td>\n",
              "      <td>Previous decision TEL-92736-18 &lt; This decision...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEL-94493-18</td>\n",
              "      <td>2018-10-31 00:00:00</td>\n",
              "      <td>2018-11-21 00:00:00</td>\n",
              "      <td>Ruth Carey (Vice Chair)</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>No other specific applications were mentioned</td>\n",
              "      <td>No</td>\n",
              "      <td>There were 7 previous application for non-paym...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CEL-72994-18</td>\n",
              "      <td>2018-03-07 00:00:00</td>\n",
              "      <td>2018-03-14 00:00:00</td>\n",
              "      <td>Avril Cardoso</td>\n",
              "      <td>Mississauga</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>No other specific applications were mentioned</td>\n",
              "      <td>No</td>\n",
              "      <td>Third Application by Landlord in past 6 months...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CEL-73021-18</td>\n",
              "      <td>2018-06-15 00:00:00</td>\n",
              "      <td>2018-06-18 00:00:00</td>\n",
              "      <td>Avril Cardoso</td>\n",
              "      <td>Mississauga</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>L1: Application to Evict a Tenant for Non-paym...</td>\n",
              "      <td>No</td>\n",
              "      <td>Tenant did not show up because hearing took pl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 50 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da50660e-a91b-488c-b72b-1d6a03125832')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da50660e-a91b-488c-b72b-1d6a03125832 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da50660e-a91b-488c-b72b-1d6a03125832');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df = pd.read_excel(file)\n",
        "df['What is the file number of the case?'] = df['What is the file number of the case?'].str.replace(' and ', ';')\n",
        "df['What is the file number of the case?'] = df['What is the file number of the case?'].str.replace(' ', ';')\n",
        "df['What is the file number of the case?'] = df['What is the file number of the case?'].str.replace('/', ';')\n",
        "df['What is the file number of the case?'] = df['What is the file number of the case?'].str.strip(';')\n",
        "df['What is the file number of the case?'] = df['What is the file number of the case?'].apply(lambda x: re.sub(REGEX, ';', x))\n",
        "df['What is the file number of the case?'] = df['What is the file number of the case?'].str.replace('File;number:;', '')\n",
        "df['What is the file number of the case?'] = df['What is the file number of the case?'].str.replace('TET-89650-18;TET-89650-18', 'TET-89650-18;TEL-90138-18')\n",
        "df = df.fillna('Not stated')\n",
        "df = df.replace('Not applicable', 'Not stated')\n",
        "df.rename(columns={\n",
        "    'If yes to the previous question, did the decision state these conditions would make moving particularly burdensome?':\n",
        "    'If any of the children had mental, medical or physical conditions, did the decision state these conditions would make moving particularly burdensome?',\n",
        "    'If yes to the previous question, which of the following were applicable to the tenant?':\n",
        "    'If the tenant had difficulty finding alternative housing for any reason, which of the following were applicable to the tenant?'    \n",
        "}, inplace=True)\n",
        "\n",
        "df = df.iloc[:, 2:-2]\n",
        "\n",
        "print(df.shape)\n",
        "df.head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3c843c20-c7ea-495a-a031-e436f556d200",
      "metadata": {
        "id": "3c843c20-c7ea-495a-a031-e436f556d200"
      },
      "outputs": [],
      "source": [
        "# df.columns   #`Timestamp` is not the time of the case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8789c210-18b6-46d6-a990-29fce2add302",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "8789c210-18b6-46d6-a990-29fce2add302",
        "outputId": "88783df1-9b67-4bce-a091-945f0623cd72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(682, 50)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  What is the file number of the case?  \\\n",
              "0                         CEL-87788-19   \n",
              "1                         CEL-90549-19   \n",
              "2                         TEL-94478-18   \n",
              "3                         TEL-94493-18   \n",
              "4                         CEL-72994-18   \n",
              "5                         CEL-73021-18   \n",
              "\n",
              "  What was the date of the hearing? [mm/dd/yyyy]  \\\n",
              "0                            2019-10-16 00:00:00   \n",
              "1                            2020-01-22 00:00:00   \n",
              "2                            2018-10-31 00:00:00   \n",
              "3                            2018-10-31 00:00:00   \n",
              "4                            2018-03-07 00:00:00   \n",
              "5                            2018-06-15 00:00:00   \n",
              "\n",
              "  What was the date of the decision? [mm/dd/yyyy]  \\\n",
              "0                             2020-06-04 00:00:00   \n",
              "1                             2020-01-10 00:00:00   \n",
              "2                             2018-11-21 00:00:00   \n",
              "3                             2018-11-21 00:00:00   \n",
              "4                             2018-03-14 00:00:00   \n",
              "5                             2018-06-18 00:00:00   \n",
              "\n",
              "  Who was the member adjudicating the decision?  \\\n",
              "0                               Sonia Anwar-Ali   \n",
              "1                               Shelby Whittick   \n",
              "2                       Ruth Carey (Vice Chair)   \n",
              "3                      Ruth Carey (Vice Chair)    \n",
              "4                                 Avril Cardoso   \n",
              "5                                 Avril Cardoso   \n",
              "\n",
              "  What was the location of the landlord tenant board?  \\\n",
              "0                                            Toronto    \n",
              "1                                        Mississauga    \n",
              "2                                            Toronto    \n",
              "3                                            Toronto    \n",
              "4                                        Mississauga    \n",
              "5                                        Mississauga    \n",
              "\n",
              "  Did the decision state the landlord was represented?  \\\n",
              "0                                                Yes     \n",
              "1                                                Yes     \n",
              "2                                                Yes     \n",
              "3                                                Yes     \n",
              "4                                                Yes     \n",
              "5                                                Yes     \n",
              "\n",
              "  Did the decision state the landlord attended the hearing?  \\\n",
              "0                                         Not stated          \n",
              "1                                                Yes          \n",
              "2                                                Yes          \n",
              "3                                                Yes          \n",
              "4                                                 No          \n",
              "5                                                 No          \n",
              "\n",
              "  Did the decision state the tenant was represented?  \\\n",
              "0                                                 No   \n",
              "1                                                 No   \n",
              "2                                                 No   \n",
              "3                                                 No   \n",
              "4                                                Yes   \n",
              "5                                                 No   \n",
              "\n",
              "  Did the decision state the tenant attended the hearing?  \\\n",
              "0                                         Not stated        \n",
              "1                                                Yes        \n",
              "2                                                Yes        \n",
              "3                                                Yes        \n",
              "4                                                 No        \n",
              "5                                                 No        \n",
              "\n",
              "  Did the decision state the landlord was a not-for-profit landlord (e.g. Toronto Community Housing)?  \\\n",
              "0                                                 No                                                    \n",
              "1                                                 No                                                    \n",
              "2                                                 No                                                    \n",
              "3                                                 No                                                    \n",
              "4                                                 No                                                    \n",
              "5                                                 No                                                    \n",
              "\n",
              "   ...  \\\n",
              "0  ...   \n",
              "1  ...   \n",
              "2  ...   \n",
              "3  ...   \n",
              "4  ...   \n",
              "5  ...   \n",
              "\n",
              "  If the tenant did propose a payment plan, did the member accept the proposed payment plan?  \\\n",
              "0                                         Not stated                                           \n",
              "1                                                 No                                           \n",
              "2                                         Not stated                                           \n",
              "3                                                Yes                                           \n",
              "4                                                 No                                           \n",
              "5                                         Not stated                                           \n",
              "\n",
              "  If a payment plan was ordered, what was the length of the payment plan?   \\\n",
              "0                                                 12                         \n",
              "1                                         Not stated                         \n",
              "2                                         Not stated                         \n",
              "3                                                  1                         \n",
              "4                                         Not stated                         \n",
              "5                                         Not stated                         \n",
              "\n",
              "  Did the decision mention the tenant’s difficulty finding alternative housing for any reason e.g.physical limitations, reliance on social assistance, etc.?  \\\n",
              "0                                                 No                                                                                                           \n",
              "1                                                 No                                                                                                           \n",
              "2                                                 No                                                                                                           \n",
              "3                                                 No                                                                                                           \n",
              "4                                                 No                                                                                                           \n",
              "5                                                 No                                                                                                           \n",
              "\n",
              "  If the tenant had difficulty finding alternative housing for any reason, which of the following were applicable to the tenant?  \\\n",
              "0                                         Not stated                                                                               \n",
              "1                                         Not stated                                                                               \n",
              "2                                         Not stated                                                                               \n",
              "3                                         Not stated                                                                               \n",
              "4                                         Not stated                                                                               \n",
              "5                                         Not stated                                                                               \n",
              "\n",
              "  Did the decision state the tenant was given prior notice for the eviction?  \\\n",
              "0                                                 No                           \n",
              "1                                                Yes                           \n",
              "2                                                Yes                           \n",
              "3                                                Yes                           \n",
              "4                                                Yes                           \n",
              "5                                                Yes                           \n",
              "\n",
              "  If the tenant was given prior notice for the eviction, how much notice was given?  \\\n",
              "0                                         Not stated                                  \n",
              "1                                         Not stated                                  \n",
              "2                                         Not stated                                  \n",
              "3                                         Not stated                                  \n",
              "4                                         Not stated                                  \n",
              "5                                         Not stated                                  \n",
              "\n",
              "  Did the decisions state postponement would result in the tenant accruing additional arrears?  \\\n",
              "0                                                 No                                             \n",
              "1                                                Yes                                             \n",
              "2                                                 No                                             \n",
              "3                                                 No                                             \n",
              "4                                                 No                                             \n",
              "5                                                 No                                             \n",
              "\n",
              "  Which other specific applications of the landlord or the tenant were mentioned?  \\\n",
              "0  L2: Application to End a Tenancy and Evict a T...                                \n",
              "1      No other specific applications were mentioned                                \n",
              "2  N13: Notice to End your Tenancy Because the La...                                \n",
              "3      No other specific applications were mentioned                                \n",
              "4      No other specific applications were mentioned                                \n",
              "5  L1: Application to Evict a Tenant for Non-paym...                                \n",
              "\n",
              "  Did the decision mention the validity of an N4 eviction notice?  \\\n",
              "0                                                 No                \n",
              "1                                                 No                \n",
              "2                                                 No                \n",
              "3                                                 No                \n",
              "4                                                 No                \n",
              "5                                                 No                \n",
              "\n",
              "  Were there detail(s) in the decision not captured by this questionnaire that should be included?  \n",
              "0  Tenant was a single mother with no support fro...                                                \n",
              "1                                         Not stated                                                \n",
              "2  Previous decision TEL-92736-18 < This decision...                                                \n",
              "3  There were 7 previous application for non-paym...                                                \n",
              "4  Third Application by Landlord in past 6 months...                                                \n",
              "5  Tenant did not show up because hearing took pl...                                                \n",
              "\n",
              "[6 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89330c7b-7e95-451c-8a86-a0960ba83b59\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>What is the file number of the case?</th>\n",
              "      <th>What was the date of the hearing? [mm/dd/yyyy]</th>\n",
              "      <th>What was the date of the decision? [mm/dd/yyyy]</th>\n",
              "      <th>Who was the member adjudicating the decision?</th>\n",
              "      <th>What was the location of the landlord tenant board?</th>\n",
              "      <th>Did the decision state the landlord was represented?</th>\n",
              "      <th>Did the decision state the landlord attended the hearing?</th>\n",
              "      <th>Did the decision state the tenant was represented?</th>\n",
              "      <th>Did the decision state the tenant attended the hearing?</th>\n",
              "      <th>Did the decision state the landlord was a not-for-profit landlord (e.g. Toronto Community Housing)?</th>\n",
              "      <th>...</th>\n",
              "      <th>If the tenant did propose a payment plan, did the member accept the proposed payment plan?</th>\n",
              "      <th>If a payment plan was ordered, what was the length of the payment plan?</th>\n",
              "      <th>Did the decision mention the tenant’s difficulty finding alternative housing for any reason e.g.physical limitations, reliance on social assistance, etc.?</th>\n",
              "      <th>If the tenant had difficulty finding alternative housing for any reason, which of the following were applicable to the tenant?</th>\n",
              "      <th>Did the decision state the tenant was given prior notice for the eviction?</th>\n",
              "      <th>If the tenant was given prior notice for the eviction, how much notice was given?</th>\n",
              "      <th>Did the decisions state postponement would result in the tenant accruing additional arrears?</th>\n",
              "      <th>Which other specific applications of the landlord or the tenant were mentioned?</th>\n",
              "      <th>Did the decision mention the validity of an N4 eviction notice?</th>\n",
              "      <th>Were there detail(s) in the decision not captured by this questionnaire that should be included?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CEL-87788-19</td>\n",
              "      <td>2019-10-16 00:00:00</td>\n",
              "      <td>2020-06-04 00:00:00</td>\n",
              "      <td>Sonia Anwar-Ali</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>12</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>L2: Application to End a Tenancy and Evict a T...</td>\n",
              "      <td>No</td>\n",
              "      <td>Tenant was a single mother with no support fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CEL-90549-19</td>\n",
              "      <td>2020-01-22 00:00:00</td>\n",
              "      <td>2020-01-10 00:00:00</td>\n",
              "      <td>Shelby Whittick</td>\n",
              "      <td>Mississauga</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No other specific applications were mentioned</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEL-94478-18</td>\n",
              "      <td>2018-10-31 00:00:00</td>\n",
              "      <td>2018-11-21 00:00:00</td>\n",
              "      <td>Ruth Carey (Vice Chair)</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>N13: Notice to End your Tenancy Because the La...</td>\n",
              "      <td>No</td>\n",
              "      <td>Previous decision TEL-92736-18 &lt; This decision...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEL-94493-18</td>\n",
              "      <td>2018-10-31 00:00:00</td>\n",
              "      <td>2018-11-21 00:00:00</td>\n",
              "      <td>Ruth Carey (Vice Chair)</td>\n",
              "      <td>Toronto</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Yes</td>\n",
              "      <td>1</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>No other specific applications were mentioned</td>\n",
              "      <td>No</td>\n",
              "      <td>There were 7 previous application for non-paym...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CEL-72994-18</td>\n",
              "      <td>2018-03-07 00:00:00</td>\n",
              "      <td>2018-03-14 00:00:00</td>\n",
              "      <td>Avril Cardoso</td>\n",
              "      <td>Mississauga</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>No other specific applications were mentioned</td>\n",
              "      <td>No</td>\n",
              "      <td>Third Application by Landlord in past 6 months...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>CEL-73021-18</td>\n",
              "      <td>2018-06-15 00:00:00</td>\n",
              "      <td>2018-06-18 00:00:00</td>\n",
              "      <td>Avril Cardoso</td>\n",
              "      <td>Mississauga</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>...</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Not stated</td>\n",
              "      <td>No</td>\n",
              "      <td>L1: Application to Evict a Tenant for Non-paym...</td>\n",
              "      <td>No</td>\n",
              "      <td>Tenant did not show up because hearing took pl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 50 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89330c7b-7e95-451c-8a86-a0960ba83b59')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89330c7b-7e95-451c-8a86-a0960ba83b59 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89330c7b-7e95-451c-8a86-a0960ba83b59');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_unique = df.drop_duplicates(subset=['What is the file number of the case?'])\n",
        "df_unique = df_unique.reset_index(drop=True)\n",
        "\n",
        "print(df_unique.shape)\n",
        "df_unique.head(6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bdce484c-64bf-465b-b5d5-205159a25ea8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdce484c-64bf-465b-b5d5-205159a25ea8",
        "outputId": "d9e2a7ef-c23c-4be4-bf4a-5d7e5d03d586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TET-89650-18;TEL-90138-18 not found. Going to the supplement directory.\n",
            "TNL-00793-18;TNL-01183-18 not found. Going to the supplement directory.\n",
            "TNL-00793-18;TNL-01183-18 not found. Going to the multiple directory.\n",
            "TNL-03299-18;TNT-00589-17 not found. Going to the supplement directory.\n",
            "TNL-03299-18;TNT-00589-17 not found. Going to the multiple directory.\n",
            "TNL-04435-18;TNL-03907-18 not found. Going to the supplement directory.\n",
            "HOL-02144-17;HOT-02146-17 not found. Going to the supplement directory.\n",
            "TEL-87475-18;TET-86819-17;TET-88355-18 not found. Going to the supplement directory.\n",
            "TEL-87475-18;TET-86819-17;TET-88355-18 not found. Going to the multiple directory.\n",
            "SWL-08112-17;SWL-08113-17 not found. Going to the supplement directory.\n",
            "SWL-12547-18;SWL-12548-18 not found. Going to the supplement directory.\n",
            "SWL-12547-18;SWL-12548-18 not found. Going to the multiple directory.\n",
            "SWL-13901-18;SWT-14627-18 not found. Going to the supplement directory.\n",
            "TEL-77442-17;TET-77790-17 not found. Going to the supplement directory.\n",
            "TEL-77442-17;TET-77790-17 not found. Going to the multiple directory.\n",
            "TEL-77505-17-RV;TEL-77505-17 not found. Going to the supplement directory.\n",
            "TEL-77505-17-RV;TEL-77505-17 not found. Going to the multiple directory.\n",
            "TNL-06025-18;TNL-06026-18 not found. Going to the supplement directory.\n",
            "TNL-06025-18;TNL-06026-18 not found. Going to the multiple directory.\n",
            "TEL-79519-17;TET-79366-17 not found. Going to the supplement directory.\n",
            "TEL-79519-17;TET-79366-17 not found. Going to the multiple directory.\n",
            "TSL-07666-19-RV not found. Going to the supplement directory.\n",
            "TSL-93207-18-RV;TST-94747-18;TSL-00082-18 not found. Going to the supplement directory.\n",
            "TSL-93207-18-RV;TST-94747-18;TSL-00082-18 not found. Going to the multiple directory.\n",
            "CEL-72209-17;CET-73173-18 not found. Going to the supplement directory.\n",
            "CEL-72209-17;CET-73173-18 not found. Going to the multiple directory.\n"
          ]
        }
      ],
      "source": [
        "info_lst = df_unique.columns[2:-2]\n",
        "\n",
        "raw_file_text = []\n",
        "\n",
        "for i in range(len(df_unique)):\n",
        "    file_no = df_unique.iloc[i,0]\n",
        "    if not os.path.isfile(text_path+file_no+'.txt'):\n",
        "        print(f'{file_no} not found. Going to the supplement directory.')\n",
        "        # passed_cases.append(file_no)\n",
        "        if not os.path.isfile(sup_path+file_no+'.txt'):\n",
        "            print(f'{file_no} not found. Going to the multiple directory.')\n",
        "            with open (multi_path+file_no+'.txt') as t:\n",
        "                # file_no_lst = file_no.split(';')\n",
        "                # print(file_no_lst)\n",
        "                raw_file_text.append(t.read())\n",
        "        else:\n",
        "            with open (sup_path+file_no+'.txt') as t:\n",
        "                raw_file_text.append(t.read())\n",
        "    else:\n",
        "        with open (text_path+file_no+'.txt') as t:\n",
        "            # cases_info[-1]['text'] = t.read()\n",
        "            raw_file_text.append(t.read())\n",
        "            # raw_file_name.append(file_no+'.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c2a92989-199d-4664-af29-f688d8a99d17",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2a92989-199d-4664-af29-f688d8a99d17",
        "outputId": "22853555-52e6-4235-93b1-daa9f7ba2a17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['If any rent increases occurred, what was the rent after the increase(s)?',\n",
              " 'If any rent increases occurred, when did the rent increase(s) come into effect? ',\n",
              " 'How many total children did the tenant have living with them? ',\n",
              " 'How many total children aged 17 or younger did the tenant have living with them?',\n",
              " 'How many total children aged 13 or younger did the tenant have living with them? ',\n",
              " 'How many total children aged 4 or younger did the tenant have living with them?',\n",
              " 'Did the decision state any of the children had mental, medical or physical conditions?',\n",
              " 'If any of the children had mental, medical or physical conditions, did the decision state these conditions would make moving particularly burdensome?',\n",
              " 'If a payment plan was ordered, what was the length of the payment plan? ',\n",
              " 'If the tenant had difficulty finding alternative housing for any reason, which of the following were applicable to the tenant?',\n",
              " 'If the tenant was given prior notice for the eviction, how much notice was given?']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# remove columns that have too little information\n",
        "little_info_col = [15, 16, 26, 27, 28, 29, 30, 31, 41, 43, 45]\n",
        "to_del = [df_unique.columns[i] for i in little_info_col]\n",
        "for col in to_del:\n",
        "    del df_unique[col]\n",
        "to_del"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "yiJ4hO2i4FEa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiJ4hO2i4FEa",
        "outputId": "b26e1bce-0b18-4772-d8b3-9880621117cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1133"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "del to_del\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d30e6a8-89c4-4054-9e7c-7251d0b27b19",
      "metadata": {
        "id": "5d30e6a8-89c4-4054-9e7c-7251d0b27b19"
      },
      "source": [
        "### Split the Train Dataframe and Validation Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "11770ff6-28de-4898-9fd9-6d1a61ceec49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11770ff6-28de-4898-9fd9-6d1a61ceec49",
        "outputId": "6878e2a7-4004-4727-e3cd-756d37d32abb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((620, 39), (62, 39))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_df = df_unique.iloc[:620, :]\n",
        "val_df = df_unique.iloc[620:, :].reset_index(drop=True)\n",
        "train_df.shape, val_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8bccb57b-0a13-46e4-8683-667c6012728b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bccb57b-0a13-46e4-8683-667c6012728b",
        "outputId": "7b0dae6e-578a-46a4-db09-ba14588a3741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 What is the file number of the case?\n",
            "1 What was the date of the hearing? [mm/dd/yyyy]\n",
            "2 What was the date of the decision? [mm/dd/yyyy]\n",
            "3 Who was the member adjudicating the decision?\n",
            "4 What was the location of the landlord tenant board?\n",
            "5 Did the decision state the landlord was represented?\n",
            "6 Did the decision state the landlord attended the hearing?\n",
            "7 Did the decision state the tenant was represented?\n",
            "8 Did the decision state the tenant attended the hearing?\n",
            "9 Did the decision state the landlord was a not-for-profit landlord (e.g. Toronto Community Housing)?\n",
            "10 Did the decision state the tenant was collecting a subsidy?\n",
            "11 What was the outcome of the case?\n",
            "12 What was the length of the tenancy, or in other words, how long had the tenants lived at the residence in question? \n",
            "13 What was the monthly rent?\n",
            "14 What was the amount of the rental deposit? \n",
            "15 What was the total amount of arrears?\n",
            "16 Over how many months did the arrears accumulate? \n",
            "17 If the tenant made a payment on the arrears after the eviction notice was served and/or prior to the hearing, what was the amount of the payment? \n",
            "18 Did the decision mention a history of arrears by the tenant separate from the arrears in the current claim (more than one period of arrears, recurrently coming in and out of arrears, arrears with previous landlord, etc.)?\n",
            "19 If the tenant had a history of arrears, did the decision mention a history of the tenant making payments on those arrears (separate from any payments made in response to the present eviction notice/hearing)?\n",
            "20 How frequently were rent payments made late?\n",
            "21 Did the member find the tenant had or seemed to have the ability to pay rent, but chose not do so?\n",
            "22 What were the specific mental, medical, or physical conditions of the tenant, if any? \n",
            "23 Did the decision state that the tenant had children living with them?\n",
            "24 Was the tenant employed at the time of the hearing?\n",
            "25 If the tenant was not employed, did the decision state the tenant was receiving any form of government assistance (e.g. OW, childcare benefits, ODSP, OSAP)?\n",
            "26 If the tenant was employed, did the decision state any doubts about the stability of employment e.g. lack of guaranteed hours, contract work, etc.?\n",
            "27 Did the member find the tenant had sufficient income to pay rent?\n",
            "28 What was the total income of the tenant’s household? \n",
            "29 Did the decision mention the tenant lost their job leading up to or during the period of the hearing?\n",
            "30 Did the decision mention any other extenuating circumstances experienced by the tenant leading up to or during the period of the claim (e.g. hospitalization, death in the family, etc.)?\n",
            "31 Did the tenant propose a payment plan?\n",
            "32 If the tenant did propose a payment plan, did the member accept the proposed payment plan?\n",
            "33 Did the decision mention the tenant’s difficulty finding alternative housing for any reason e.g.physical limitations, reliance on social assistance, etc.?\n",
            "34 Did the decision state the tenant was given prior notice for the eviction?\n",
            "35 Did the decisions state postponement would result in the tenant accruing additional arrears?\n",
            "36 Which other specific applications of the landlord or the tenant were mentioned?\n",
            "37 Did the decision mention the validity of an N4 eviction notice?\n",
            "38 Were there detail(s) in the decision not captured by this questionnaire that should be included?\n"
          ]
        }
      ],
      "source": [
        "for i, q in enumerate(train_df.columns):\n",
        "    print(i, q)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c6b48eb-461e-4095-ac93-6ac04bfe3a7a",
      "metadata": {
        "id": "3c6b48eb-461e-4095-ac93-6ac04bfe3a7a"
      },
      "source": [
        "## Initialize the Tokenizer and the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "71a21b6e-9a0b-40ef-962c-c06aa39e3e1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71a21b6e-9a0b-40ef-962c-c06aa39e3e1a",
        "outputId": "8f043566-20a5-4632-831a-f2cba9f2332a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForQuestionAnswering: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LongformerForQuestionAnswering were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# @article{Beltagy2020Longformer,\n",
        "#   title={Longformer: The Long-Document Transformer},\n",
        "#   author={Iz Beltagy and Matthew E. Peters and Arman Cohan},\n",
        "#   journal={arXiv:2004.05150},\n",
        "#   year={2020},\n",
        "# }\n",
        "tokenizer1 = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "model1 = LongformerForQuestionAnswering.from_pretrained('allenai/longformer-base-4096', gradient_checkpointing=True)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False)\n",
        "\n",
        "# ref: https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_tune_Longformer_Encoder_Decoder_(LED)_for_Summarization_on_pubmed.ipynb#scrollTo=jpUr9QeebZ-n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7074c9d3-c565-428b-9fcb-c65962fd4fa7",
      "metadata": {
        "id": "7074c9d3-c565-428b-9fcb-c65962fd4fa7"
      },
      "source": [
        "## A Test before Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "54b8e886-5018-4924-9b6e-9dc7c85f5b17",
      "metadata": {
        "id": "54b8e886-5018-4924-9b6e-9dc7c85f5b17"
      },
      "outputs": [],
      "source": [
        "def prompt(dataframe, raw_texts):\n",
        "    input_texts = []\n",
        "    outputs = []\n",
        "    # long_cases = 0\n",
        "    \n",
        "    questions = dataframe.columns\n",
        "    \n",
        "    for q_no in range(len(questions)):\n",
        "        answers = dataframe.iloc[:,q_no]\n",
        "        # print(len(raw_texts), len(answers))\n",
        "        assert len(raw_texts) == len(answers)\n",
        "\n",
        "        for i in range(len(answers)):\n",
        "            full_text = raw_texts[i]\n",
        "            text = full_text[full_text.find('Content:')+len('Content:'):]\n",
        "\n",
        "            # if len(text) > 26000:\n",
        "            #     # print(len(text))\n",
        "            #     text = text[:26000]\n",
        "            #     long_cases += 1\n",
        "\n",
        "            text = text.replace('\\n', ' ')\n",
        "            text = text.replace('\\xa0', ' ')\n",
        "            text = text.replace('\\t', ' ')\n",
        "            text = text.replace('   ', ' ').replace('  ', ' ').replace('  ', ' ').replace('  ', ' ')\n",
        "            # text\n",
        "            # for word in stop_words:\n",
        "            #     text = text.replace(' '+word+' ', ' ')\n",
        "\n",
        "            if 'Schedule 1' in text:\n",
        "                s_idx = text.find('Schedule 1')\n",
        "                text = text[:s_idx]\n",
        "\n",
        "            input_text = f'Question: {questions[q_no]} Text: {text}'  \n",
        "            input_texts.append(input_text)\n",
        "\n",
        "            output = str(answers[i])\n",
        "            outputs.append(output)\n",
        "        \n",
        "    # print(len(input_texts), len(outputs))\n",
        "    # print(input_texts[0], outputs[0]) \n",
        "    # print(long_cases)\n",
        "    return input_texts, outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68c815b4-b341-4a6f-a183-9f6a3071342e",
      "metadata": {
        "id": "68c815b4-b341-4a6f-a183-9f6a3071342e"
      },
      "source": [
        "### Longformer for Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1124a45e-2dcc-4b1a-8a4a-8786d106a29b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "1124a45e-2dcc-4b1a-8a4a-8786d106a29b",
        "outputId": "1ed0d28e-0b8e-4b90-9953-6e80621fe62b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CEL-87788-19\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "q1_lst, a1_lst = prompt(df_unique, raw_file_text)\n",
        "q1 = q1_lst[0]\n",
        "a1 = a1_lst[0]\n",
        "# # print(q1)\n",
        "print(a1)\n",
        "encoding = tokenizer1.encode_plus(text=q1,\n",
        "                                  text_pair=a1) \n",
        "                                 # add_special=True)\n",
        "inputs = torch.LongTensor(encoding['input_ids']).unsqueeze(0)  #Token embeddings\n",
        "attention_mask = torch.LongTensor(encoding['attention_mask']).unsqueeze(0)\n",
        "# print(len(attention_mask))\n",
        "\n",
        "# sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
        "tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids']) #input tokens\n",
        "outputs = model1(input_ids=inputs, \n",
        "                attention_mask=attention_mask)\n",
        "start_scores, end_scores = outputs[0], outputs[1]\n",
        "answer_tokens = tokens[torch.argmax(start_scores):torch.argmax(end_scores)+1]\n",
        "answer = tokenizer1.decode(tokenizer1.convert_tokens_to_ids(answer_tokens))\n",
        "answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "73690cd1-d7b3-4769-8c45-14c9bb46b7d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73690cd1-d7b3-4769-8c45-14c9bb46b7d8",
        "outputId": "38df7ffc-3d2e-4f9e-eed7-4114ab139a68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(999), tensor(655))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "torch.argmax(start_scores),torch.argmax(end_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32dc7330-7248-4199-95d5-dc8c4377fd70",
      "metadata": {
        "id": "32dc7330-7248-4199-95d5-dc8c4377fd70"
      },
      "source": [
        "It shows that the encoder models can not really get what we need for most columns. Therefore we will"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2En5ikSpz2Ja",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2En5ikSpz2Ja",
        "outputId": "e95e7231-aa59-417b-a289-f2fffde195f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "del tokenizer1, model1#, answer\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90024f6b-527e-48a3-8d04-d4e3440dae7f",
      "metadata": {
        "id": "90024f6b-527e-48a3-8d04-d4e3440dae7f"
      },
      "source": [
        "###  Longformer Encoder-Decoder (LED) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c3d7ce61-f8f2-49ea-83fd-658a992b28d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3d7ce61-f8f2-49ea-83fd-658a992b28d8",
        "outputId": "e0f88eb2-ec57-451e-b2f7-fb70d2f33ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1364]) torch.Size([1, 1364])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "q1_lst, a1_lst = prompt(df_unique, raw_file_text)\n",
        "q1 = q1_lst[0]\n",
        "a1 = a1_lst[0]\n",
        "# # print(q1)\n",
        "input_encoding = tokenizer(q1)\n",
        "output_encoding = tokenizer(a1)\n",
        "input_ids = torch.LongTensor(encoding['input_ids']).unsqueeze(0)  # batch of size 1\n",
        "attention_mask = torch.LongTensor(encoding['attention_mask']).unsqueeze(0)\n",
        "# attention_mask[:, [1, 4, 21,]] =  2  # Set global attention based on the task. For example,\n",
        "                                     # classification: the <s> token\n",
        "                                     # QA: question tokens\n",
        "print(input_ids.shape, attention_mask.shape)\n",
        "# input_ids, attention_mask = pad_to_window_size(\n",
        "#         input_ids, attention_mask, config.attention_window[0], tokenizer.pad_token_id)\n",
        "\n",
        "output = model.generate(\n",
        "    input_ids=input_ids, \n",
        "    attention_mask=attention_mask,\n",
        "    return_dict_in_generate=True, \n",
        "    output_scores=False, \n",
        "    max_length=512,\n",
        "    temperature=0.5,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=3.0,\n",
        "    top_k=10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2fe6927d-8529-4c5f-9e10-1093bc3b4af0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fe6927d-8529-4c5f-9e10-1093bc3b4af0",
        "outputId": "580cdc8b-1054-4055-a350-6ca1919e61ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"</s><s>Question: What is the file number of this case? Text.  Order under Section 69 Residential Tenancies Act, 2006 File Number (a) CEL-87788 and a copy for use in an application to terminate tenancy The Landlord may apply at any time on or compositional basis that he/she has been persistently late paying his rent since 2012. 1 Pertinently subjecting her tenant(s), M., K.(the 'Tenant') could not be convicted by reason thereof; it would have required him as proof otherwise than evidence before me if I was permitted against my will with respect thereto whereupon there were no documentary evidences presented during trial proceedings relating only one point after each day until such period expires from June 30th 2017 through September 29’ 2018 which shall also require compensation when due but do so prior notice being made within three months following payment date thereafter unless further notices are issued pursuantto section 78). 2 BUDGETTY THE LEGAL ORDER TO END ANTIENSION 3 In accordance wit all other terms described above herein we propose applying jointly without delay while continuing our review process whereby these acts take effect immediately upon receipt… 4Budgetty applies directly towards payment Amount owing $190 per month till December 31st 2019The amount owed amounts payable include interest taken out along portion five days later including those deducted over six weeks between March 16 & April 24, 2020 accordingly listed below : This term consists solely consistingof payments received once every 6months beginning May 15 – July 14–20 respectively plus accrued interests calculated annually based off year zero sum paid up excepted unearned Interest calculate From August 17 - February 18Â 2022andInterest calculation derived monthly average rates assessed yearly On account applicable tax rate computed daily ) Date Issued …June 10 January 2031January 25,, 2021DateIssuing today Ms Anwar Ali Case issuled Today's Notice To Endorsements For Sale TENANT NOTICE OF REASON FOR RELIEF Listening Period begins hereinheretending order ‘I am sorry you cannot continue your lease' list includes information about why she did what She testified earlier said….TENDERARY LETTER ONCE HER TERM OFFICE SHE alleges That Her total annual income does NOT COMPARED WITH ANY OTHER INFORMATION 5A2E3 If found guilty because You can prove No Evidence Before Me Is Not Required By Lawany Other matters related unto thee Court Objective Hearing continues...She submitted written testimony regarding how much money neededBy law i findthat [Act] requires minimum\"]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "tokenizer.batch_decode(output['sequences'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6187bfc0-e4a0-4e75-a160-927a01a238fd",
      "metadata": {
        "id": "6187bfc0-e4a0-4e75-a160-927a01a238fd"
      },
      "source": [
        "## Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ec29c7d3-df9c-4dad-85e3-1f41d9509f55",
      "metadata": {
        "id": "ec29c7d3-df9c-4dad-85e3-1f41d9509f55"
      },
      "outputs": [],
      "source": [
        "def preprocess(dataframe, tokenizer, raw_texts):\n",
        "    input_texts, outputs = prompt(dataframe, raw_texts)   \n",
        "    \n",
        "    input_toks = tokenizer.batch_encode_plus(input_texts,\n",
        "                                             add_special_tokens=False, \n",
        "                                             return_token_type_ids=False)\n",
        "    output_toks = tokenizer.batch_encode_plus(outputs, \n",
        "                                              add_special_tokens=False,\n",
        "                                              return_token_type_ids=False)\n",
        "    # print(len(q1_train_input['input_ids']), len(q1_train_output['input_ids']))\n",
        "    return input_toks, output_toks\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a9af30ba-541e-4354-9959-3ce2d6180b3b",
      "metadata": {
        "id": "a9af30ba-541e-4354-9959-3ce2d6180b3b"
      },
      "outputs": [],
      "source": [
        "train_raw_texts = raw_file_text[:620]\n",
        "val_raw_texts = raw_file_text[620:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "17862bd4-1c23-4844-af6e-4d60697bad20",
      "metadata": {
        "id": "17862bd4-1c23-4844-af6e-4d60697bad20"
      },
      "outputs": [],
      "source": [
        "train_input, train_output = preprocess(train_df, tokenizer, train_raw_texts)\n",
        "val_input, val_output = preprocess(val_df, tokenizer, val_raw_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "418537eb-6804-4d9e-88ec-47ddb4acc13a",
      "metadata": {
        "id": "418537eb-6804-4d9e-88ec-47ddb4acc13a"
      },
      "outputs": [],
      "source": [
        "# len(q1_train_input['input_ids']), len(q1_train_output['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "622c1563-5d3a-4b8a-8378-db1f08f51c89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "622c1563-5d3a-4b8a-8378-db1f08f51c89",
        "outputId": "ddd361cc-da9b-4f43-ccc4-95f19867138e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input length: 2\n",
            "Input example:\n",
            " Question: What is the file number of the case? Text:  Order under Section 69 Residential Tenancies A\n",
            " \n",
            "Input ID example:\n",
            " [45641, 35, 653, 16, 5, 2870, 346, 9, 5, 403, 116, 14159, 35, 1437, 9729, 223, 7162, 5913, 21796, 4527, 27661, 1783, 6, 3503, 8655, 12270, 35, 230, 3721, 12, 27806, 4652, 12, 1646, 256, 4, 347, 4, 36, 627, 128, 26902, 30669, 27645, 5049, 13, 41, 645, 7, 22335, 5, 43921, 8, 39369, 256, 4, 530, 4, 36, 627, 128, 28612, 927, 27645, 142, 37, 34, 57, 16403, 7240, 628, 11, 2746, 39, 5956, 4, 20, 3192, 30669, 67, 1695, 4660, 13, 349, 183, 5, 4527, 927, 2442, 11, 5, 1933, 71, 5, 17829, 1248, 4, 152, 2502, 21]\n",
            " \n",
            "Tokens:\n",
            " ['Question', ':', 'ĠWhat', 'Ġis', 'Ġthe', 'Ġfile', 'Ġnumber', 'Ġof', 'Ġthe', 'Ġcase', '?', 'ĠText', ':', 'Ġ', 'ĠOrder', 'Ġunder', 'ĠSection', 'Ġ69', 'ĠResidential', 'ĠTen', 'ancies', 'ĠAct', ',', 'Ġ2006', 'ĠFile', 'ĠNumber', ':', 'ĠC', 'EL', '-', '877', '88', '-', '19', 'ĠM', '.', 'C', '.', 'Ġ(', 'the', \"Ġ'\", 'Land', 'lord', \"')\", 'Ġapplied', 'Ġfor', 'Ġan', 'Ġorder', 'Ġto', 'Ġterminate', 'Ġthe', 'Ġtenancy', 'Ġand', 'Ġevict', 'ĠM', '.', 'K', '.', 'Ġ(', 'the', \"Ġ'\", 'Ten', 'ant', \"')\", 'Ġbecause', 'Ġhe', 'Ġhas', 'Ġbeen', 'Ġpersist', 'ently', 'Ġlate', 'Ġin', 'Ġpaying', 'Ġhis', 'Ġrent', '.', 'ĠThe', 'ĠLand', 'lord', 'Ġalso', 'Ġclaimed', 'Ġcompensation', 'Ġfor', 'Ġeach', 'Ġday', 'Ġthe', 'ĠTen', 'ant', 'Ġremained', 'Ġin', 'Ġthe', 'Ġunit', 'Ġafter', 'Ġthe', 'Ġtermination', 'Ġdate', '.', 'ĠThis', 'Ġapplication', 'Ġwas']\n",
            " \n",
            "Attention Mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \n",
            "Output example:\n",
            " CEL-87788-19\n",
            " \n",
            "Output ID example:\n",
            " [347, 3721, 12, 27806, 4652, 12, 1646]\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# for BertTokenizer\n",
        "print(\"Input length:\", len(train_input))\n",
        "# print(\" \")\n",
        "print(\"Input example:\\n\", tokenizer.decode(train_input['input_ids'][0])[:100])\n",
        "print(\" \")\n",
        "print(\"Input ID example:\\n\", train_input['input_ids'][0][:100])\n",
        "print(\" \")\n",
        "print(\"Tokens:\\n\", [tokenizer.convert_ids_to_tokens(id) for id in train_input['input_ids'][0]][:100])\n",
        "print(\" \")\n",
        "print(\"Attention Mask:\", train_input['attention_mask'][0])\n",
        "print(\" \")\n",
        "print(\"Output example:\\n\", tokenizer.decode(train_output['input_ids'][0])[:100])\n",
        "print(\" \")\n",
        "print(\"Output ID example:\\n\", train_output['input_ids'][0])\n",
        "print(\" \")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b35e16a7-ebb9-4656-8af7-543c1e90a717",
      "metadata": {
        "id": "b35e16a7-ebb9-4656-8af7-543c1e90a717"
      },
      "source": [
        "## Create the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a0129cf5-ec8a-4792-a1a2-6da338a99b4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0129cf5-ec8a-4792-a1a2-6da338a99b4c",
        "outputId": "27097eaa-91b8-45d1-85b8-8702054962c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "PAD = tokenizer.pad_token_id\n",
        "SEP = tokenizer.sep_token_id\n",
        "PAD, SEP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9827de32-c0fa-4591-886d-11270507e4b7",
      "metadata": {
        "id": "9827de32-c0fa-4591-886d-11270507e4b7"
      },
      "outputs": [],
      "source": [
        "class CaseDataset(Dataset):\n",
        "\n",
        "    def __init__(self, inputs, outputs):\n",
        "        self.inputs = inputs\n",
        "        self.outputs = outputs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_ids = self.inputs['input_ids'][idx]\n",
        "        attention_mask = self.inputs['attention_mask'][idx]\n",
        "\n",
        "        target_ids = self.outputs['input_ids'][idx]\n",
        "        # target_attention_mask = self.outputs['attention_mask'][idx]\n",
        "        return {\"input_ids\": input_ids, \"attention_mask\":attention_mask, \"output_ids\":target_ids}\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    batch_input = [torch.LongTensor(example['input_ids']) for example in batch]\n",
        "    batch_output = [torch.LongTensor(example['output_ids']) for example in batch]\n",
        "    batch_mask = [torch.LongTensor(example['attention_mask']) for example in batch]\n",
        "\n",
        "    padded_batch_input_ids = pad_sequence(batch_input, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    padded_batch_label = pad_sequence(batch_output, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    padded_batch_att_mask = pad_sequence(batch_mask, batch_first=True, padding_value=-100)\n",
        "\n",
        "    return {\"input_ids\": padded_batch_input_ids, \"attention_mask\": padded_batch_att_mask, \"labels\": padded_batch_label}\n",
        "\n",
        "\n",
        "def to_device(data, device):\n",
        "    new_data = {}\n",
        "    for k in data:\n",
        "        new_data[k] = data[k].to(device)\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51g7EdVXFSsA",
      "metadata": {
        "id": "51g7EdVXFSsA"
      },
      "source": [
        "## Prepare the Functions for Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7g9cTXxmFW4m",
      "metadata": {
        "id": "7g9cTXxmFW4m"
      },
      "outputs": [],
      "source": [
        "def train(model:nn.Module, train_loader:DataLoader, optimizer:optim.Optimizer, log_step=200):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    log_loss = 0.0\n",
        "    for idx, batch in enumerate(train_loader):\n",
        "        # try:\n",
        "        model.zero_grad()\n",
        "        batch = to_device(batch, device)\n",
        "        loss = model(**batch).loss\n",
        "        # print(loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        log_loss += loss.item()\n",
        "\n",
        "        # wandb.log({'batch':idx, 'train_loss': loss.item()})\n",
        "        # wandb.log({'batch':idx, 'accumulated_train_loss_in_this_Q': log_loss})\n",
        "\n",
        "        if idx % log_step == 0:\n",
        "            print(f\"Train Step: {idx} Loss: {log_loss / log_step}\")\n",
        "            log_loss = 0.0\n",
        "        # except:\n",
        "        #     print(f'The text is too long. Passing for now. Step No: {idx}')\n",
        "        #     pass\n",
        "\n",
        "    return epoch_loss / len(train_loader)\n",
        "        \n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model:nn.Module, eval_loader:DataLoader):\n",
        "    eval_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    for batch in eval_loader:\n",
        "        batch = to_device(batch, device)\n",
        "        output = model(**batch)\n",
        "        loss = output.loss\n",
        "        eval_loss += loss.item()\n",
        "        pred = output.logits.argmax(-1)\n",
        "        label = batch[\"labels\"]\n",
        "        correct += torch.where(label!=-100, pred==label, 0).sum().item()\n",
        "        total += torch.sum(label != -100).item()\n",
        "    \n",
        "    print(total, correct)\n",
        "\n",
        "    eval_acc = correct / total\n",
        "    eval_loss = eval_loss / len(eval_loader) \n",
        "    return eval_acc, eval_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "I5aO_Z5aFfXd",
      "metadata": {
        "id": "I5aO_Z5aFfXd"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def answer(model, loader):\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    model.eval()\n",
        "    for batch in loader:\n",
        "        batch = to_device(batch, device)\n",
        "        input_ids = batch[\"input_ids\"]\n",
        "        attention_mask = batch[\"attention_mask\"]\n",
        "        labels = batch[\"labels\"]\n",
        "        outputs = model.generate(input_ids=input_ids, \n",
        "                                 attention_mask=attention_mask, \n",
        "                                 return_dict_in_generate=True, \n",
        "                                 pad_token_id=tokenizer.pad_token_id, \n",
        "                                 max_length=512, \n",
        "                                 top_k=15)\n",
        "        \n",
        "        decode_texts = tokenizer.batch_decode([l[l != 0] for l in outputs['sequences']])\n",
        "        gold_texts = tokenizer.batch_decode([l[l != 0] for l in labels])\n",
        "        # print(decode_texts, gold_texts)\n",
        "        for gold, decode in zip(gold_texts, decode_texts):\n",
        "            l = gold.replace(' ', '').replace('</s>', '').replace('<pad>','').replace('<s>', '')\n",
        "            p = decode.replace(' ', '').replace('</s>', '').replace('<pad>','').replace('<s>', '')\n",
        "\n",
        "            # if '<pad>' in gold:\n",
        "            #     l_pad_idx = gold.index('<pad>')\n",
        "            #     l = gold[:l_pad_idx].replace(' ', '').replace('</s>', '').replace('<pad>','').replace('<s>', '')\n",
        "            # else:\n",
        "            #     l = gold.replace(' ', '').replace('</s>', '').replace('<pad>','').replace('<s>', '')\n",
        "            \n",
        "            # if '<pad>' in decode:\n",
        "            #     p_pad_idx = decode.index('<pad>')\n",
        "            #     p = decode[:p_pad_idx].replace(' ', '').replace('</s>', '').replace('<pad>','').replace('<s>', '')\n",
        "            # else:\n",
        "            #     p = decode.replace(' ', '').replace('</s>', '').replace('<pad>','').replace('<s>', '')\n",
        "\n",
        "            # print(l, p)\n",
        "            all_labels.append(l)\n",
        "            all_preds.append(p)\n",
        "    \n",
        "    return all_preds, all_labels\n",
        "\n",
        "\n",
        "def accuracy(sys, gold):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for s, g in zip(sys, gold):\n",
        "        if s == g:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "            \n",
        "    accuracy = correct / total\n",
        "    return accuracy, correct, total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "138d0350-47e2-4ccb-b446-a5a91486a83d",
      "metadata": {
        "id": "138d0350-47e2-4ccb-b446-a5a91486a83d"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "TTCb0PgEWrMc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTCb0PgEWrMc",
        "outputId": "70de8083-57e9-4a0b-e41c-817e78c3734f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LEDForConditionalGeneration(\n",
              "  (led): LEDModel(\n",
              "    (shared): Embedding(50265, 768, padding_idx=1)\n",
              "    (encoder): LEDEncoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): LEDLearnedPositionalEmbedding(16384, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x LEDEncoderLayer(\n",
              "          (self_attn): LEDEncoderAttention(\n",
              "            (longformer_self_attn): LEDEncoderSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
              "            )\n",
              "            (output): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): LEDDecoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): LEDLearnedPositionalEmbedding(1024, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x LEDDecoderLayer(\n",
              "          (self_attn): LEDDecoderAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): LEDDecoderAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "397ac1ed-f2f6-4fef-a998-f1d7cf9ad156",
      "metadata": {
        "id": "397ac1ed-f2f6-4fef-a998-f1d7cf9ad156"
      },
      "outputs": [],
      "source": [
        "# Experiment\n",
        "train_dataset = CaseDataset(train_input, train_output)\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, collate_fn=collate_fn, shuffle=True)\n",
        "\n",
        "val_dataset = CaseDataset(val_input, val_output) \n",
        "val_loader = DataLoader(val_dataset, batch_size=2, collate_fn=collate_fn, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del df, train_dataset\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxBndeAsIpE_",
        "outputId": "cb32c207-6809-4885-edbf-10af7368f25e"
      },
      "id": "xxBndeAsIpE_",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b03fcf01-187c-4e5e-8e11-595205323057",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b03fcf01-187c-4e5e-8e11-595205323057",
        "outputId": "cd2cd43a-ac6c-4b1e-b0d5-6e8c60d43cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Train Step: 0 Loss: 0.08910118103027344\n",
            "Train Step: 200 Loss: 3.8606323892623187\n",
            "Train Step: 400 Loss: 2.2938519670069217\n",
            "Train Step: 600 Loss: 1.8507057175785304\n",
            "Train Step: 800 Loss: 1.799031710922718\n",
            "Train Step: 1000 Loss: 1.6885197733156383\n",
            "Train Step: 1200 Loss: 1.4644999227393418\n",
            "Train Step: 1400 Loss: 1.3922516457084566\n",
            "Train Step: 1600 Loss: 1.3874541073152795\n",
            "Train Step: 1800 Loss: 1.1951215607766061\n",
            "Train Step: 2000 Loss: 1.2154717954900116\n",
            "Train Step: 2200 Loss: 1.2600497307279148\n",
            "Train Step: 2400 Loss: 1.271074233725667\n",
            "Train Step: 2600 Loss: 1.157466769590974\n",
            "Train Step: 2800 Loss: 0.9989672024827451\n",
            "Train Step: 3000 Loss: 1.1186609284952282\n",
            "Train Step: 3200 Loss: 1.077932654884644\n",
            "Train Step: 3400 Loss: 0.9908759119268506\n",
            "Train Step: 3600 Loss: 1.1118535865144805\n",
            "Train Step: 3800 Loss: 1.0885822320636362\n",
            "Train Step: 4000 Loss: 0.9163184484001249\n",
            "Train Step: 4200 Loss: 0.9476255435030907\n",
            "Train Step: 4400 Loss: 2.9698772474378345\n",
            "Train Step: 4600 Loss: 2.013804636746645\n",
            "Train Step: 4800 Loss: 1.2056668946379796\n",
            "Train Step: 5000 Loss: 1.1211163768172263\n",
            "Train Step: 5200 Loss: 1.0903447223827243\n",
            "Train Step: 5400 Loss: 0.9600956901162863\n",
            "Train Step: 5600 Loss: 1.1440635614143684\n",
            "Train Step: 5800 Loss: 1.098586515900679\n",
            "Train Step: 6000 Loss: 1.158345774752088\n",
            "Train Step: 6200 Loss: 1.1277124860114418\n",
            "Train Step: 6400 Loss: 1.1156172680761665\n",
            "Train Step: 6600 Loss: 1.0503828799608164\n",
            "Train Step: 6800 Loss: 0.8918450367636979\n",
            "Train Step: 7000 Loss: 1.0092129244538954\n",
            "Train Step: 7200 Loss: 0.9072635094635189\n",
            "Train Step: 7400 Loss: 0.8789686599210836\n",
            "Train Step: 7600 Loss: 1.250271422136575\n",
            "Train Step: 7800 Loss: 1.1466645602323116\n",
            "Train Step: 8000 Loss: 0.916956170015037\n",
            "Train Step: 8200 Loss: 0.9482599093392491\n",
            "Train Step: 8400 Loss: 0.9590710770012811\n",
            "Train Step: 8600 Loss: 1.0667364086746238\n",
            "Train Step: 8800 Loss: 0.9842238310305401\n",
            "Train Step: 9000 Loss: 0.7616182120516897\n",
            "Train Step: 9200 Loss: 0.9606268631154671\n",
            "Train Step: 9400 Loss: 0.9117919091554358\n",
            "Train Step: 9600 Loss: 0.9750938842073082\n",
            "Train Step: 9800 Loss: 0.9538158125570044\n",
            "Train Step: 10000 Loss: 0.8910327303875237\n",
            "Train Step: 10200 Loss: 0.7332510477118194\n",
            "Train Step: 10400 Loss: 0.8391777759487741\n",
            "Train Step: 10600 Loss: 0.9724943996872752\n",
            "Train Step: 10800 Loss: 0.860643771062605\n",
            "Train Step: 11000 Loss: 1.0614745397493244\n",
            "Train Step: 11200 Loss: 0.6952581795025616\n",
            "Train Step: 11400 Loss: 0.8107847616123035\n",
            "Train Step: 11600 Loss: 0.9034689940692624\n",
            "Train Step: 11800 Loss: 0.928081044703722\n",
            "Train Step: 12000 Loss: 0.9754620318673551\n",
            "Epoch 1 Training Loss: 1.1892273034971585\n",
            "10850 8518\n",
            "Epoch 0 Eval Acc: 0.7850691244239631; Eval Loss: 0.9343382263083528\n",
            "Epoch 2:\n",
            "Train Step: 0 Loss: 0.00505860686302185\n",
            "Train Step: 200 Loss: 0.7830718213459477\n",
            "Train Step: 400 Loss: 0.6705000852164812\n",
            "Train Step: 600 Loss: 0.7979405495803803\n",
            "Train Step: 800 Loss: 0.7584071192564443\n",
            "Train Step: 1000 Loss: 0.7718102142203134\n",
            "Train Step: 1200 Loss: 0.8854461546428501\n",
            "Train Step: 1400 Loss: 0.8688439488434233\n",
            "Train Step: 1600 Loss: 0.8382127850642428\n",
            "Train Step: 1800 Loss: 0.8281660475255922\n",
            "Train Step: 2000 Loss: 0.7583151222669403\n",
            "Train Step: 2200 Loss: 0.9385258043126669\n",
            "Train Step: 2400 Loss: 0.7597608812293037\n",
            "Train Step: 2600 Loss: 0.7227778649842367\n",
            "Train Step: 2800 Loss: 0.7628293587756343\n",
            "Train Step: 3000 Loss: 0.9261514798365533\n",
            "Train Step: 3200 Loss: 0.7826160903973505\n",
            "Train Step: 3400 Loss: 0.7998788863932714\n",
            "Train Step: 3600 Loss: 0.9053052348457277\n",
            "Train Step: 3800 Loss: 0.6897385357972234\n",
            "Train Step: 4000 Loss: 0.8491518667177297\n",
            "Train Step: 4200 Loss: 0.6789127512741834\n",
            "Train Step: 4400 Loss: 0.7935074846632779\n",
            "Train Step: 4600 Loss: 0.7635710988845676\n",
            "Train Step: 4800 Loss: 0.7962241817614994\n",
            "Train Step: 5000 Loss: 0.7852056112379069\n",
            "Train Step: 5200 Loss: 0.86108558149077\n",
            "Train Step: 5400 Loss: 0.8390205460705329\n",
            "Train Step: 5600 Loss: 0.8542845394671894\n",
            "Train Step: 5800 Loss: 0.8986312805209309\n",
            "Train Step: 6000 Loss: 1.0007333203451707\n",
            "Train Step: 6200 Loss: 0.9525853903964162\n",
            "Train Step: 6400 Loss: 0.8317241831263528\n",
            "Train Step: 6600 Loss: 0.8286109520541504\n",
            "Train Step: 6800 Loss: 0.7715109732840211\n",
            "Train Step: 7000 Loss: 0.847954380386509\n",
            "Train Step: 7200 Loss: 0.7287024961411953\n",
            "Train Step: 7400 Loss: 0.7936962355440482\n",
            "Train Step: 7600 Loss: 0.8063742740405724\n",
            "Train Step: 7800 Loss: 0.7771434712363408\n",
            "Train Step: 8000 Loss: 0.8121508981892839\n",
            "Train Step: 8200 Loss: 0.841382407451747\n",
            "Train Step: 8400 Loss: 0.8084611122077331\n",
            "Train Step: 8600 Loss: 0.7671654171007686\n",
            "Train Step: 8800 Loss: 0.8078616623952984\n",
            "Train Step: 9000 Loss: 0.7930453789420426\n",
            "Train Step: 9200 Loss: 0.7375591944018379\n",
            "Train Step: 9400 Loss: 0.8245711041847243\n",
            "Train Step: 9600 Loss: 0.8192022175085731\n",
            "Train Step: 9800 Loss: 0.8002832851815037\n",
            "Train Step: 10000 Loss: 0.7264121423708275\n",
            "Train Step: 10200 Loss: 0.6913874358590693\n",
            "Train Step: 10400 Loss: 0.7655340709723533\n",
            "Train Step: 10600 Loss: 0.7967999923182651\n",
            "Train Step: 10800 Loss: 0.8566402236162685\n",
            "Train Step: 11000 Loss: 0.8671715927217156\n",
            "Train Step: 11200 Loss: 0.7153938355250284\n",
            "Train Step: 11400 Loss: 0.8242481022607535\n",
            "Train Step: 11600 Loss: 0.6953308240394108\n",
            "Train Step: 11800 Loss: 0.7522532089566812\n",
            "Train Step: 12000 Loss: 0.694613474283833\n",
            "Epoch 2 Training Loss: 0.8023542334453919\n",
            "10850 8815\n",
            "Epoch 1 Eval Acc: 0.812442396313364; Eval Loss: 0.7754495724060436\n",
            "Epoch 3:\n",
            "Train Step: 0 Loss: 0.0006364727020263672\n",
            "Train Step: 200 Loss: 0.6494437792387907\n",
            "Train Step: 400 Loss: 0.7538451084995177\n",
            "Train Step: 600 Loss: 0.8169765854440629\n",
            "Train Step: 800 Loss: 0.7436345928744413\n",
            "Train Step: 1000 Loss: 0.6599326191062573\n",
            "Train Step: 1200 Loss: 0.7405406438093632\n",
            "Train Step: 1400 Loss: 0.753192174253054\n",
            "Train Step: 1600 Loss: 0.6822780274576508\n",
            "Train Step: 1800 Loss: 0.7223023251071572\n",
            "Train Step: 2000 Loss: 0.6491453835507854\n",
            "Train Step: 2200 Loss: 0.7759881045040674\n",
            "Train Step: 2400 Loss: 0.57173211043817\n",
            "Train Step: 2600 Loss: 0.6931305228709244\n",
            "Train Step: 2800 Loss: 0.7503239394538105\n",
            "Train Step: 3000 Loss: 0.6456555836182087\n",
            "Train Step: 3200 Loss: 0.7225631706696004\n",
            "Train Step: 3400 Loss: 0.6792879685037769\n",
            "Train Step: 3600 Loss: 0.6477389447763562\n",
            "Train Step: 3800 Loss: 0.7300627513194923\n",
            "Train Step: 4000 Loss: 0.6115173732396215\n",
            "Train Step: 4200 Loss: 0.694194332138868\n",
            "Train Step: 4400 Loss: 0.721559551123064\n",
            "Train Step: 4600 Loss: 0.6724906283745077\n",
            "Train Step: 4800 Loss: 0.697368522239849\n",
            "Train Step: 5000 Loss: 0.6761800316744484\n",
            "Train Step: 5200 Loss: 0.6481140937190503\n",
            "Train Step: 5400 Loss: 0.6922457286855206\n",
            "Train Step: 5600 Loss: 0.7208750988950487\n",
            "Train Step: 5800 Loss: 0.6900019505666569\n",
            "Train Step: 6000 Loss: 0.7534396994719281\n",
            "Train Step: 6200 Loss: 0.6950921144348103\n",
            "Train Step: 6400 Loss: 0.5869047420297284\n",
            "Train Step: 6600 Loss: 0.869007410320919\n",
            "Train Step: 6800 Loss: 0.7280254948441871\n",
            "Train Step: 7000 Loss: 0.6473545026156353\n",
            "Train Step: 7200 Loss: 0.6797345721290913\n",
            "Train Step: 7400 Loss: 0.7630979323241627\n",
            "Train Step: 7600 Loss: 0.6785099991620518\n",
            "Train Step: 7800 Loss: 0.6239302563294769\n",
            "Train Step: 8000 Loss: 0.7211693348432892\n",
            "Train Step: 8200 Loss: 0.6822885576728731\n",
            "Train Step: 8400 Loss: 0.7845298175141215\n",
            "Train Step: 8600 Loss: 0.7713438162696548\n",
            "Train Step: 8800 Loss: 0.73116013339255\n",
            "Train Step: 9000 Loss: 0.5775920121918898\n",
            "Train Step: 9200 Loss: 0.7760477297881152\n",
            "Train Step: 9400 Loss: 0.8245801146910526\n",
            "Train Step: 9600 Loss: 0.7298831873887685\n",
            "Train Step: 9800 Loss: 0.7271878108754755\n",
            "Train Step: 10000 Loss: 0.8465576116507872\n",
            "Train Step: 10200 Loss: 0.6631984608183847\n",
            "Train Step: 10400 Loss: 0.9021093216678128\n",
            "Train Step: 10600 Loss: 0.6238016597321256\n",
            "Train Step: 10800 Loss: 0.8237003113795072\n",
            "Train Step: 11000 Loss: 0.7310131994471886\n",
            "Train Step: 11200 Loss: 0.6255611663451418\n",
            "Train Step: 11400 Loss: 0.5402062192570883\n",
            "Train Step: 11600 Loss: 0.6854410207044566\n",
            "Train Step: 11800 Loss: 0.7066907739732414\n",
            "Train Step: 12000 Loss: 0.7212707674270495\n",
            "Epoch 3 Training Loss: 0.7072757187638614\n",
            "10850 8887\n",
            "Epoch 2 Eval Acc: 0.8190783410138249; Eval Loss: 0.7844730143279934\n"
          ]
        }
      ],
      "source": [
        "# experiment\n",
        "epochs = 3\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
        "\n",
        "model.train()\n",
        "\n",
        "# print(f\"Training Question 1\")\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}:\")\n",
        "    \n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    print(f\"Epoch {epoch+1} Training Loss: {train_loss}\")\n",
        "\n",
        "    eval_acc, eval_loss = evaluate(model, val_loader)\n",
        "    print(f\"Epoch {epoch} Eval Acc: {eval_acc}; Eval Loss: {eval_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "KvK52Tbdw8iK",
      "metadata": {
        "id": "KvK52Tbdw8iK"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/gdrive/My Drive/595/led_3epoch_law_allqs.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "83VqUx8O3KJ-",
      "metadata": {
        "id": "83VqUx8O3KJ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c13ef4-c55b-4663-92d7-ce9f7f66924f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 161,844,480 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f08715d-09c9-498c-b462-6fc8bdeaaef9",
      "metadata": {
        "id": "2f08715d-09c9-498c-b462-6fc8bdeaaef9"
      },
      "source": [
        "## Evaluate the Model on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "fzRTdJMxxUuA",
      "metadata": {
        "id": "fzRTdJMxxUuA"
      },
      "outputs": [],
      "source": [
        "def q_prompt(dataframe, q_no, raw_texts):\n",
        "    input_texts = []\n",
        "    outputs = []\n",
        "    # long_cases = 0\n",
        "    \n",
        "    questions = dataframe.columns\n",
        "    answers = dataframe.iloc[:,q_no]\n",
        "    # print(len(raw_texts), len(answers))\n",
        "    assert len(raw_texts) == len(answers)\n",
        "\n",
        "    for i in range(len(answers)):\n",
        "        full_text = raw_texts[i]\n",
        "        text = full_text[full_text.find('Content:')+len('Content:'):]\n",
        "\n",
        "        # if len(text) > 26000:\n",
        "        #     # print(len(text))\n",
        "        #     text = text[:26000]\n",
        "        #     long_cases += 1\n",
        "\n",
        "        text = text.replace('\\n', ' ')\n",
        "        text = text.replace('\\xa0', ' ')\n",
        "        text = text.replace('\\t', ' ')\n",
        "        text = text.replace('   ', ' ').replace('  ', ' ').replace('  ', ' ').replace('  ', ' ')\n",
        "        # text\n",
        "        # for word in stop_words:\n",
        "        #     text = text.replace(' '+word+' ', ' ')\n",
        "\n",
        "        if 'Schedule 1' in text:\n",
        "            s_idx = text.find('Schedule 1')\n",
        "            text = text[:s_idx]\n",
        "\n",
        "        input_text = f'Question: {questions[q_no]} Text: {text}'  \n",
        "        input_texts.append(input_text)\n",
        "\n",
        "        output = str(answers[i])\n",
        "        outputs.append(output)\n",
        "        \n",
        "    print(len(input_texts), len(outputs))\n",
        "    # print(input_texts[0], outputs[0]) \n",
        "    # print(long_cases)\n",
        "    return input_texts, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "befdc206-7015-4f50-bc66-a85553ed9f92",
      "metadata": {
        "id": "befdc206-7015-4f50-bc66-a85553ed9f92"
      },
      "outputs": [],
      "source": [
        "def q_preprocess(dataframe, q_no, tokenizer, raw_texts):\n",
        "    input_texts, outputs = prompt(dataframe, raw_texts)   \n",
        "    \n",
        "    input_toks = tokenizer.batch_encode_plus(input_texts,\n",
        "                                             add_special_tokens=False, \n",
        "                                             return_token_type_ids=False)\n",
        "    output_toks = tokenizer.batch_encode_plus(outputs, \n",
        "                                              add_special_tokens=False,\n",
        "                                              return_token_type_ids=False)\n",
        "    # print(len(q1_train_input['input_ids']), len(q1_train_output['input_ids']))\n",
        "    return input_toks, output_toks\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "4d06cafb-044f-4ee4-9e1b-02cd524eb48a",
      "metadata": {
        "id": "4d06cafb-044f-4ee4-9e1b-02cd524eb48a"
      },
      "outputs": [],
      "source": [
        "def get_test_dataloader(df, q_no, tokenizer, raw_texts):\n",
        "    input_toks, output_toks = q_preprocess(df, q_no, tokenizer, raw_texts)\n",
        "    dataset = CaseDataset(input_toks, output_toks)\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size=8, \n",
        "                            collate_fn=collate_fn, \n",
        "                            shuffle=False)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "0171ba31-1819-40f3-81bb-982876ee0490",
      "metadata": {
        "id": "0171ba31-1819-40f3-81bb-982876ee0490"
      },
      "outputs": [],
      "source": [
        "def answer_qs(val_df, q_no, tokenizer):\n",
        "    loader = get_test_dataloader(val_df, q_no, tokenizer, val_raw_texts)\n",
        "    # print(len(loader))\n",
        "    \n",
        "    questions = val_df.columns\n",
        "    print(f'Q{q_no+1}: {questions[q_no]}')\n",
        "    \n",
        "    preds, golds = answer(model, loader)\n",
        "    acc, correct, total = accuracy(preds, golds)\n",
        "    acc = round(acc, 5)\n",
        "    \n",
        "    print(f\"Accuracy for this question is: {acc*100}%\")\n",
        "    print('')\n",
        "    \n",
        "    return acc, preds"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del train_df, train_loader, count_parameters\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ-PNbF8C9ao",
        "outputId": "8ee73119-ceb7-4c4d-d768-2e1e76ba5348"
      },
      "id": "JJ-PNbF8C9ao",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "678fe51c-6ee9-4955-aadf-f1ba49dd1498",
      "metadata": {
        "id": "678fe51c-6ee9-4955-aadf-f1ba49dd1498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "ad1c0529-e9d5-4677-f6d8-3087ae69eac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q1: What is the file number of the case?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-57975995349c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Q{i+1}: {val_df.columns[i]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_qs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0macc_lst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-f26f5c60e97f>\u001b[0m in \u001b[0;36manswer_qs\u001b[0;34m(val_df, q_no, tokenizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Q{q_no+1}: {questions[q_no]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-926066b37bf3>\u001b[0m in \u001b[0;36manswer\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         outputs = model.generate(input_ids=input_ids, \n\u001b[0m\u001b[1;32m     12\u001b[0m                                  \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                  \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;31m# if model is encoder decoder encoder_outputs are created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/led/modeling_led.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1894\u001b[0m                     )\n\u001b[1;32m   1895\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1896\u001b[0;31m                     layer_outputs = encoder_layer(\n\u001b[0m\u001b[1;32m   1897\u001b[0m                         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/led/modeling_led.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m    971\u001b[0m         \"\"\"\n\u001b[1;32m    972\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m         attn_outputs = self.self_attn(\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/led/modeling_led.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;34m\"\"\"Input shape: Batch x Time x Channel\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         self_outputs = self.longformer_self_attn(\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/led/modeling_led.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mkey_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         attn_scores = self._sliding_chunks_query_key_matmul(\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mquery_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_sided_attn_window_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/led/modeling_led.py\u001b[0m in \u001b[0;36m_sliding_chunks_query_key_matmul\u001b[0;34m(self, query, key, window_overlap)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;31m# bcyd: batch_size * num_heads x chunks x 2window_overlap x head_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;31m# bcxy: batch_size * num_heads x chunks x 2window_overlap x 2window_overlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdiagonal_chunked_attention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bcxd,bcyd->bcxy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# multiply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;31m# convert diagonals into columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# recurse incase operands contains value that has torch function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;31m# in the original implementation this line is omitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_einsum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# the path for contracting 0 or 1 time(s) is already optimized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# or the user has disabled using opt_einsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.88 GiB (GPU 0; 15.77 GiB total capacity; 11.73 GiB already allocated; 1.34 GiB free; 13.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "acc_lst = []\n",
        "with open ('longformer_q_by_q_preds.txt', 'w') as p:\n",
        "    for i in range(0, val_df.shape[1]):\n",
        "        p.write(f'Q{i+1}: {val_df.columns[i]}')\n",
        "        acc, preds = answer_qs(val_df, i, tokenizer)\n",
        "        acc_lst.append(acc)\n",
        "        print(preds)\n",
        "        p.write(str(preds)+'\\n')\n",
        "        p.write('\\n')\n",
        "avg_acc = sum(acc_lst) / len(acc_lst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6ca6ea8-98f1-4176-8860-8db3297cd171",
      "metadata": {
        "id": "f6ca6ea8-98f1-4176-8860-8db3297cd171"
      },
      "outputs": [],
      "source": [
        "assert len(acc_lst) == 39\n",
        "acc_lst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77eeaa6f-b594-4082-897d-23c4f9d54605",
      "metadata": {
        "id": "77eeaa6f-b594-4082-897d-23c4f9d54605"
      },
      "outputs": [],
      "source": [
        "with open ('longformer_all_qs_preds.txt', 'w') as p:\n",
        "    for pred in preds_lst:\n",
        "        p.write(str(pred)+'\\n')\n",
        "        p.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m47IvKfggdNh",
      "metadata": {
        "id": "m47IvKfggdNh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}