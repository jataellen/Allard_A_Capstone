{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def read_csv_with_lists(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Iterate over each column\n",
    "    for column in df.columns:\n",
    "        # Check if the column contains strings that represent lists\n",
    "        if df[column].dtype == object:\n",
    "            try:\n",
    "                # Convert the strings to lists using ast.literal_eval\n",
    "                df[column] = df[column].apply(ast.literal_eval)\n",
    "            except (ValueError, SyntaxError):\n",
    "                # Skip the column if it cannot be converted to a list\n",
    "                pass\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_case_outcome\n",
      "No relief            430\n",
      "Relief               235\n",
      "Conditional Order      7\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_file_text</th>\n",
       "      <th>raw_file_name</th>\n",
       "      <th>full_cleaned</th>\n",
       "      <th>metadata</th>\n",
       "      <th>content</th>\n",
       "      <th>case_citation</th>\n",
       "      <th>file_number</th>\n",
       "      <th>language</th>\n",
       "      <th>year</th>\n",
       "      <th>ltb_location</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>hearing_date</th>\n",
       "      <th>url</th>\n",
       "      <th>adjudicating_member</th>\n",
       "      <th>new_case_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metadata:\\nDate:\\t2017-01-18\\nFile number:\\t\\n...</td>\n",
       "      <td>CEL-62600-16.txt</td>\n",
       "      <td>[Metadata:, Date: 2017-01-18, File number:, CE...</td>\n",
       "      <td>[Date: 2017-01-18, File number:, CEL-62600-16,...</td>\n",
       "      <td>[Arrears Worksheet File Number: CEL-62600-16 T...</td>\n",
       "      <td>CEL-62600-16 (Re), 2017 CanLII 9545 (ON LTB)</td>\n",
       "      <td>CEL-62600-16</td>\n",
       "      <td>English</td>\n",
       "      <td>2016</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>01/18/2017</td>\n",
       "      <td>01/30/2017</td>\n",
       "      <td>https://canlii.ca/t/gxq6n</td>\n",
       "      <td>Avril Cardoso</td>\n",
       "      <td>No relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metadata:\\nDate:\\t2017-01-09\\nFile number:\\t\\n...</td>\n",
       "      <td>CEL-62852-16.txt</td>\n",
       "      <td>[Metadata:, Date: 2017-01-09, File number:, CE...</td>\n",
       "      <td>[Date: 2017-01-09, File number:, CEL-62852-16,...</td>\n",
       "      <td>[Arrears Worksheet File Number: CEL-62852-16 T...</td>\n",
       "      <td>CEL-62852-16 (Re), 2017 CanLII 9535 (ON LTB)</td>\n",
       "      <td>CEL-62852-16</td>\n",
       "      <td>English</td>\n",
       "      <td>2016</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>01/09/2017</td>\n",
       "      <td>01/09/2017</td>\n",
       "      <td>https://canlii.ca/t/gxq6r</td>\n",
       "      <td>Tiisetso Russell</td>\n",
       "      <td>Relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Metadata:\\nDate:\\t2017-01-09\\nFile number:\\t\\n...</td>\n",
       "      <td>CEL-63024-16.txt</td>\n",
       "      <td>[Metadata:, Date: 2017-01-09, File number:, CE...</td>\n",
       "      <td>[Date: 2017-01-09, File number:, CEL-63024-16,...</td>\n",
       "      <td>[Arrears Worksheet File Number: CEL-63024-16 T...</td>\n",
       "      <td>CEL-63024-16 (Re), 2017 CanLII 9543 (ON LTB)</td>\n",
       "      <td>CEL-63024-16</td>\n",
       "      <td>English</td>\n",
       "      <td>2016</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>01/09/2017</td>\n",
       "      <td>01/09/2017</td>\n",
       "      <td>https://canlii.ca/t/gxq6s</td>\n",
       "      <td>Tiisetso Russell</td>\n",
       "      <td>Relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metadata:\\nDate:\\t2017-01-20\\nFile number:\\t\\n...</td>\n",
       "      <td>CEL-63056-16.txt</td>\n",
       "      <td>[Metadata:, Date: 2017-01-20, File number:, CE...</td>\n",
       "      <td>[Date: 2017-01-20, File number:, CEL-63056-16,...</td>\n",
       "      <td>[Arrears Worksheet File Number: CEL-63056-16 T...</td>\n",
       "      <td>CEL-63056-16 (Re), 2017 CanLII 9537 (ON LTB)</td>\n",
       "      <td>CEL-63056-16</td>\n",
       "      <td>English</td>\n",
       "      <td>2016</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>01/09/2017</td>\n",
       "      <td>01/09/2017</td>\n",
       "      <td>https://canlii.ca/t/gxq6t</td>\n",
       "      <td>Tiisetso Russell</td>\n",
       "      <td>No relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Metadata:\\nDate:\\t2017-02-03\\nFile number:\\t\\n...</td>\n",
       "      <td>CEL-63193-16.txt</td>\n",
       "      <td>[Metadata:, Date: 2017-02-03, File number:, CE...</td>\n",
       "      <td>[Date: 2017-02-03, File number:, CEL-63193-16,...</td>\n",
       "      <td>[Arrears Worksheet File Number: CEL-63193-16 T...</td>\n",
       "      <td>CEL-63193-16 (Re), 2017 CanLII 30828 (ON LTB)</td>\n",
       "      <td>CEL-63193-16</td>\n",
       "      <td>English</td>\n",
       "      <td>2016</td>\n",
       "      <td>Mississauga</td>\n",
       "      <td>01/10/2017</td>\n",
       "      <td>02/03/2017</td>\n",
       "      <td>https://canlii.ca/t/h3w7b</td>\n",
       "      <td>Karen Wallace</td>\n",
       "      <td>No relief</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       raw_file_text     raw_file_name  \\\n",
       "0  Metadata:\\nDate:\\t2017-01-18\\nFile number:\\t\\n...  CEL-62600-16.txt   \n",
       "1  Metadata:\\nDate:\\t2017-01-09\\nFile number:\\t\\n...  CEL-62852-16.txt   \n",
       "2  Metadata:\\nDate:\\t2017-01-09\\nFile number:\\t\\n...  CEL-63024-16.txt   \n",
       "3  Metadata:\\nDate:\\t2017-01-20\\nFile number:\\t\\n...  CEL-63056-16.txt   \n",
       "4  Metadata:\\nDate:\\t2017-02-03\\nFile number:\\t\\n...  CEL-63193-16.txt   \n",
       "\n",
       "                                        full_cleaned  \\\n",
       "0  [Metadata:, Date: 2017-01-18, File number:, CE...   \n",
       "1  [Metadata:, Date: 2017-01-09, File number:, CE...   \n",
       "2  [Metadata:, Date: 2017-01-09, File number:, CE...   \n",
       "3  [Metadata:, Date: 2017-01-20, File number:, CE...   \n",
       "4  [Metadata:, Date: 2017-02-03, File number:, CE...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  [Date: 2017-01-18, File number:, CEL-62600-16,...   \n",
       "1  [Date: 2017-01-09, File number:, CEL-62852-16,...   \n",
       "2  [Date: 2017-01-09, File number:, CEL-63024-16,...   \n",
       "3  [Date: 2017-01-20, File number:, CEL-63056-16,...   \n",
       "4  [Date: 2017-02-03, File number:, CEL-63193-16,...   \n",
       "\n",
       "                                             content  \\\n",
       "0  [Arrears Worksheet File Number: CEL-62600-16 T...   \n",
       "1  [Arrears Worksheet File Number: CEL-62852-16 T...   \n",
       "2  [Arrears Worksheet File Number: CEL-63024-16 T...   \n",
       "3  [Arrears Worksheet File Number: CEL-63056-16 T...   \n",
       "4  [Arrears Worksheet File Number: CEL-63193-16 T...   \n",
       "\n",
       "                                   case_citation   file_number language  year  \\\n",
       "0   CEL-62600-16 (Re), 2017 CanLII 9545 (ON LTB)  CEL-62600-16  English  2016   \n",
       "1   CEL-62852-16 (Re), 2017 CanLII 9535 (ON LTB)  CEL-62852-16  English  2016   \n",
       "2   CEL-63024-16 (Re), 2017 CanLII 9543 (ON LTB)  CEL-63024-16  English  2016   \n",
       "3   CEL-63056-16 (Re), 2017 CanLII 9537 (ON LTB)  CEL-63056-16  English  2016   \n",
       "4  CEL-63193-16 (Re), 2017 CanLII 30828 (ON LTB)  CEL-63193-16  English  2016   \n",
       "\n",
       "  ltb_location decision_date hearing_date                        url  \\\n",
       "0  Mississauga    01/18/2017   01/30/2017  https://canlii.ca/t/gxq6n   \n",
       "1  Mississauga    01/09/2017   01/09/2017  https://canlii.ca/t/gxq6r   \n",
       "2  Mississauga    01/09/2017   01/09/2017  https://canlii.ca/t/gxq6s   \n",
       "3  Mississauga    01/09/2017   01/09/2017  https://canlii.ca/t/gxq6t   \n",
       "4  Mississauga    01/10/2017   02/03/2017  https://canlii.ca/t/h3w7b   \n",
       "\n",
       "  adjudicating_member new_case_outcome  \n",
       "0       Avril Cardoso        No relief  \n",
       "1    Tiisetso Russell           Relief  \n",
       "2    Tiisetso Russell           Relief  \n",
       "3    Tiisetso Russell        No relief  \n",
       "4       Karen Wallace        No relief  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df = read_csv_with_lists('data/outcome_extraction_testing.csv')\n",
    "print(gold_df.value_counts('new_case_outcome'))\n",
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # row = 0\n",
    "\n",
    "# keyword = \"accordance with\"\n",
    "# # keyword = \"based on\"\n",
    "# # keyword = \"considered\"\n",
    "\n",
    "# found_total = 0\n",
    "\n",
    "# for row in gold_df.index:\n",
    "#     gold_outcome = gold_df.loc[row, 'new_case_outcome']\n",
    "#     # print(gold_outcome)\n",
    "\n",
    "#     case_text = \" \".join(gold_df.loc[row, 'content'])\n",
    "#     # if case_text.find(keyword) != -1:\n",
    "#     if keyword in case_text.lower():\n",
    "#         found_total += 1\n",
    "\n",
    "# print(f\"{found_total / len(gold_df.index)}; {found_total} / {len(gold_df.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_boundary = \"accordance with\"\n",
    "# end_boundary = \"ordered that\"\n",
    "\n",
    "# found_total = 0\n",
    "\n",
    "# max_outcome_len = 0\n",
    "# total_outcome_lens = []\n",
    "\n",
    "# for row in gold_df.index:\n",
    "#     gold_outcome = gold_df.loc[row, 'new_case_outcome']\n",
    "\n",
    "#     case_text = \" \".join(gold_df.loc[row, 'content'])\n",
    "#     start_bound_positions = find_all_positions(case_text.lower(), start_boundary)\n",
    "\n",
    "#     proximity = 1000 # number of characters after the start boundary to look for the end boundary\n",
    "\n",
    "#     for pos in start_bound_positions:\n",
    "#         near_text = case_text[pos - 100 : pos + int(proximity)]\n",
    "#         near_text = \". \".join(near_text.split(\". \")[1:])\n",
    "\n",
    "#         # Use a while loop to increase the proximity if end_boundary is not found in near_text\n",
    "#         while end_boundary not in near_text and proximity < len(case_text) - pos:\n",
    "#             proximity *= 1.5\n",
    "#             near_text = case_text[pos - 100 : pos + int(proximity)]\n",
    "#             near_text = \". \".join(near_text.split(\". \")[1:])\n",
    "\n",
    "#         end_bounds_finds = find_all_positions(near_text, end_boundary)\n",
    "\n",
    "#         if end_boundary in near_text:\n",
    "#             found_total += 1\n",
    "#             subset2 = near_text[:near_text.find(end_boundary)]\n",
    "#             outcome = \". \".join(subset2.split(\". \")[:-1])\n",
    "#             outcome = re.sub(r'^\\d+\\.\\s*', '', outcome).strip() # removes \"16. \" from start of string\n",
    "#             gold_df.loc[row, 'outcome_text'] = outcome\n",
    "#             outcome_len = len(outcome.split(' '))\n",
    "#             if outcome_len > max_outcome_len:\n",
    "#                 max_outcome_len = outcome_len\n",
    "#             total_outcome_lens.append(outcome_len)\n",
    "#             break\n",
    "#         else:\n",
    "#             gold_df.loc[row, 'outcome_text'] = \"NEED OTHER METHOD\"\n",
    "\n",
    "#     # Reset the proximity back to the original value for the next row\n",
    "#     proximity = 1000\n",
    "\n",
    "# print(found_total / len(gold_df.index))\n",
    "# print(max_outcome_len)\n",
    "# print(sum(total_outcome_lens) / len(gold_df.index))\n",
    "# print(sorted(total_outcome_lens)[len(total_outcome_lens) // 2])\n",
    "# print(len([val for val in total_outcome_lens if val > 300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     print(gold_df['outcome_text'].tolist()[i])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://canlii.ca/t/hs1b8\n",
      "No relief\n",
      "41\n",
      "I have considered all of the disclosed circumstances in accordance with subsection 83(2) of the Residential Tenancies Act, 2006 (the 'Act'), and find that it would not be necessary to grant relief from eviction pursuant to subsection 83(1) of the Act.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import itertools\n",
    "\n",
    "def find_all_positions(text, keyword):\n",
    "    \"\"\"\n",
    "    Finds all positions of a keyword in a given text.\n",
    "\n",
    "    This function searches for a keyword in a given text and returns a list of positions where the keyword is found.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The text to search within.\n",
    "    keyword : str\n",
    "        The keyword to find in the text.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of integers representing the positions of the keyword in the text.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> find_all_positions(\"This is an example sentence.\", \"example\")\n",
    "    [11]\n",
    "    \"\"\"\n",
    "    positions = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        index = text.find(keyword, start)\n",
    "        if index == -1:\n",
    "            break\n",
    "        positions.append(index)\n",
    "        start = index + 1\n",
    "    return positions\n",
    "\n",
    "def get_outcome_span(text):\n",
    "    \"\"\"\n",
    "    Extracts the outcome span from a given text using different methods.\n",
    "\n",
    "    This function extracts the outcome span from a given text using multiple methods. It first attempts to find\n",
    "    the span between occurrences of the phrases \"accordance with\" and \"ordered\". If that method fails, it then\n",
    "    tries to find the span after the phrase \"it is ordered\". If that also fails, it looks for the span after the\n",
    "    phrase \"find\". The function returns the extracted outcome span as a cleaned string.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The text from which to extract the outcome span.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str or None\n",
    "        The extracted outcome span as a cleaned string, or None if no span is found.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> get_outcome_span(unstructured_case_file)\n",
    "    \"In accordance with the order, it is ordered that the defendant pays a fine.\"\n",
    "    \"\"\"\n",
    "\n",
    "    ############### FIRST METHOD ################\n",
    "\n",
    "    # find all occurrences of 'accordance with' and 'ordered'\n",
    "    accordance_with_indices = [m.end() for m in re.finditer('accordance', text)]\n",
    "    ordered_indices = [m.start() for m in re.finditer('ordered', text)]\n",
    "\n",
    "    # generate all possible pairs of indices\n",
    "    index_pairs = list(itertools.product(accordance_with_indices, ordered_indices))\n",
    "\n",
    "    # filter pairs where 'accordance with' index is less than 'ordered' index\n",
    "    index_pairs = [(i, j) for (i, j) in index_pairs if i < j]\n",
    "    if index_pairs:\n",
    "        # find the pair with the shortest distance between indices\n",
    "        min_distance_pair = min(index_pairs, key = lambda x: x[1] - x[0])\n",
    "        try:\n",
    "            best_subset = text[min_distance_pair[0] - 200 : min_distance_pair[1] + 400].strip()\n",
    "        except IndexError:\n",
    "            best_subset = text[min_distance_pair[0] - 200 : min_distance_pair[1]].strip()\n",
    "\n",
    "        # best_subset = text[min_distance_pair[0] - 200 : min_distance_pair[1] + 400].strip()\n",
    "        best_subset = best_subset.split(\". \")\n",
    "\n",
    "        sent_id = [idx for idx, i in enumerate(best_subset) if \"accordance\" in i.lower()][0]\n",
    "\n",
    "        best_subset = best_subset[sent_id]\n",
    "        clean_outcome = re.sub(r'\\[\\d+\\]', '', best_subset)\n",
    "        clean_outcome = re.sub(r'^\\d+\\.\\s*', '', clean_outcome).strip() # removes numbers from the start of the string such as \"16. \" from start of string\n",
    "\n",
    "        # return None\n",
    "        # print(\"METHOD 1\")\n",
    "\n",
    "        # if the outcome doesn't end with a period, add one. it looks nicer :)\n",
    "        if clean_outcome[-1] != \".\":\n",
    "            return clean_outcome + \".\"\n",
    "        return clean_outcome\n",
    "    \n",
    "    ################ SECOND METHOD ################\n",
    "\n",
    "    keyword = \"it is ordered\"\n",
    "    if keyword in text.lower():\n",
    "        matches = find_all_positions(text.lower(), keyword)\n",
    "\n",
    "        for match in matches:\n",
    "            try: # match + 400 chars\n",
    "                substr = \". \".join(text[match - 200 : match + 400].split(\". \")[1:-1]) \n",
    "            except IndexError: # match idx until end of string (+ 400 is sometimes out of range)\n",
    "                substr = \". \".join(text[match - 400 :].split(\". \")[1:-1])\n",
    "            clean_outcome = re.sub(r'\\[\\d+\\]', '', substr)\n",
    "            clean_outcome = re.sub(r'^\\d+\\.\\s*', '', clean_outcome).strip()\n",
    "            \n",
    "            # return None\n",
    "            # print(\"METHOD 2\")\n",
    "            if clean_outcome:\n",
    "                # if the outcome doesn't end with a period, add one. it looks nicer :)\n",
    "                if clean_outcome[-1] != \".\":\n",
    "                    return clean_outcome + \".\"\n",
    "                return clean_outcome\n",
    "            \n",
    "            # this somehow returns nothing, continue to the next example\n",
    "            continue\n",
    "\n",
    "    ############### THIRD METHOD ################\n",
    "\n",
    "    keyword = \" find \" # spaces to prevent \"finding\" or other derivations from being included -- specifically looking for statements like \"I find that...\"\n",
    "    if keyword in text.lower():\n",
    "        matches = find_all_positions(text.lower(), keyword)\n",
    "        for match in matches:\n",
    "\n",
    "            try: # match + 400 chars\n",
    "                substr = \". \".join(text[match - 200 : match + 400].split(\". \")[1:-1]) \n",
    "            except IndexError: # match idx until end of string (+ 400 is sometimes out of range)\n",
    "                substr = \". \".join(text[match - 400 :].split(\". \")[1:-1])\n",
    "            clean_outcome = re.sub(r'\\[\\d+\\]', '', substr) # gets ride of \n",
    "            clean_outcome = re.sub(r'^\\d+\\.\\s*', '', clean_outcome).strip()\n",
    "\n",
    "            # return None\n",
    "\n",
    "            # if the outcome doesn't end with a period, add one. it looks nicer :)\n",
    "            # print(\"METHOD 3\")\n",
    "\n",
    "            if clean_outcome:\n",
    "                # if the outcome doesn't end with a period, add one. it looks nicer :)\n",
    "                if clean_outcome[-1] != \".\":\n",
    "                    return clean_outcome + \".\"\n",
    "                return clean_outcome\n",
    "            \n",
    "            # this somehow returns nothing, continue to the next example\n",
    "            continue\n",
    "\n",
    "    # if absolutely nothing works, return none and try Longformer or something idk\n",
    "    return None\n",
    "\n",
    "test_row = 51\n",
    "# for test_row in range(100):\n",
    "test_str = \" \".join(gold_df.loc[test_row, 'content'])\n",
    "print(gold_df.loc[test_row, 'url'])\n",
    "print(gold_df.loc[test_row, 'new_case_outcome'])\n",
    "cospan = get_outcome_span(test_str)\n",
    "if cospan:\n",
    "    print(len(cospan.split()))\n",
    "    print(cospan)\n",
    "    # print(\"ROW\", test_row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on all Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>raw_file_name</th>\n",
       "      <th>raw_file_text</th>\n",
       "      <th>full_cleaned</th>\n",
       "      <th>metadata</th>\n",
       "      <th>content</th>\n",
       "      <th>language</th>\n",
       "      <th>case_citation</th>\n",
       "      <th>file_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>NOL-10723-12.txt</td>\n",
       "      <td>Metadata:\\nDate:\\t2013-01-08\\nFile number:\\t\\n...</td>\n",
       "      <td>[Metadata:, Date: 2013-01-08, File number:, NO...</td>\n",
       "      <td>[Date: 2013-01-08, File number:, NOL-10723-12,...</td>\n",
       "      <td>[Order under Section 69, Residential Tenancies...</td>\n",
       "      <td>English</td>\n",
       "      <td>NOL-10723-12 (Re), 2013 CanLII 5182 (ON LTB)</td>\n",
       "      <td>NOL-10723-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>TNL-43964-13.txt</td>\n",
       "      <td>Metadata:\\nDate:\\t2013-05-02\\nFile number:\\t\\n...</td>\n",
       "      <td>[Metadata:, Date: 2013-05-02, File number:, TN...</td>\n",
       "      <td>[Date: 2013-05-02, File number:, TNL-43964-13,...</td>\n",
       "      <td>[Order under section 69 Residential Tenancies ...</td>\n",
       "      <td>English</td>\n",
       "      <td>TNL-43964-13 (Re), 2013 CanLII 36866 (ON LTB)</td>\n",
       "      <td>TNL-43964-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>TNL-45470-13.txt</td>\n",
       "      <td>Metadata:\\nDate:\\t2013-06-17\\nFile number:\\t\\n...</td>\n",
       "      <td>[Metadata:, Date: 2013-06-17, File number:, TN...</td>\n",
       "      <td>[Date: 2013-06-17, File number:, TNL-45470-13,...</td>\n",
       "      <td>[Order under Section 69 Residential Tenancies ...</td>\n",
       "      <td>English</td>\n",
       "      <td>TNL-45470-13 (Re), 2013 CanLII 44492 (ON LTB)</td>\n",
       "      <td>TNL-45470-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>TEL-33159-13; \\n TET-33272-13.txt</td>\n",
       "      <td>Metadata:\\nDate:\\t2013-02-25\\nFile number:\\t\\n...</td>\n",
       "      <td>[Metadata:, Date: 2013-02-25, File number:, TE...</td>\n",
       "      <td>[Date: 2013-02-25, File number:, TEL-33159-13;...</td>\n",
       "      <td>[Order under sections 31 and 69 Residential Te...</td>\n",
       "      <td>English</td>\n",
       "      <td>TEL-33159-13 (Re), 2013 CanLII 50418 (ON LTB)</td>\n",
       "      <td>TEL-33159-13; TET-33272-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>TNL-39747-12.txt</td>\n",
       "      <td>Metadata:\\nDate:\\t2013-02-07\\nFile number:\\t\\n...</td>\n",
       "      <td>[Metadata:, Date: 2013-02-07, File number:, TN...</td>\n",
       "      <td>[Date: 2013-02-07, File number:, TNL-39747-12,...</td>\n",
       "      <td>[Order under Section 68 Residential Tenancies ...</td>\n",
       "      <td>English</td>\n",
       "      <td>TNL-39747-12 (Re), 2013 CanLII 10834 (ON LTB)</td>\n",
       "      <td>TNL-39747-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                      raw_file_name  \\\n",
       "0  2013                   NOL-10723-12.txt   \n",
       "1  2013                   TNL-43964-13.txt   \n",
       "2  2013                   TNL-45470-13.txt   \n",
       "3  2013  TEL-33159-13; \\n TET-33272-13.txt   \n",
       "4  2013                   TNL-39747-12.txt   \n",
       "\n",
       "                                       raw_file_text  \\\n",
       "0  Metadata:\\nDate:\\t2013-01-08\\nFile number:\\t\\n...   \n",
       "1  Metadata:\\nDate:\\t2013-05-02\\nFile number:\\t\\n...   \n",
       "2  Metadata:\\nDate:\\t2013-06-17\\nFile number:\\t\\n...   \n",
       "3  Metadata:\\nDate:\\t2013-02-25\\nFile number:\\t\\n...   \n",
       "4  Metadata:\\nDate:\\t2013-02-07\\nFile number:\\t\\n...   \n",
       "\n",
       "                                        full_cleaned  \\\n",
       "0  [Metadata:, Date: 2013-01-08, File number:, NO...   \n",
       "1  [Metadata:, Date: 2013-05-02, File number:, TN...   \n",
       "2  [Metadata:, Date: 2013-06-17, File number:, TN...   \n",
       "3  [Metadata:, Date: 2013-02-25, File number:, TE...   \n",
       "4  [Metadata:, Date: 2013-02-07, File number:, TN...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  [Date: 2013-01-08, File number:, NOL-10723-12,...   \n",
       "1  [Date: 2013-05-02, File number:, TNL-43964-13,...   \n",
       "2  [Date: 2013-06-17, File number:, TNL-45470-13,...   \n",
       "3  [Date: 2013-02-25, File number:, TEL-33159-13;...   \n",
       "4  [Date: 2013-02-07, File number:, TNL-39747-12,...   \n",
       "\n",
       "                                             content language  \\\n",
       "0  [Order under Section 69, Residential Tenancies...  English   \n",
       "1  [Order under section 69 Residential Tenancies ...  English   \n",
       "2  [Order under Section 69 Residential Tenancies ...  English   \n",
       "3  [Order under sections 31 and 69 Residential Te...  English   \n",
       "4  [Order under Section 68 Residential Tenancies ...  English   \n",
       "\n",
       "                                   case_citation                 file_number  \n",
       "0   NOL-10723-12 (Re), 2013 CanLII 5182 (ON LTB)                NOL-10723-12  \n",
       "1  TNL-43964-13 (Re), 2013 CanLII 36866 (ON LTB)                TNL-43964-13  \n",
       "2  TNL-45470-13 (Re), 2013 CanLII 44492 (ON LTB)                TNL-45470-13  \n",
       "3  TEL-33159-13 (Re), 2013 CanLII 50418 (ON LTB)  TEL-33159-13; TET-33272-13  \n",
       "4  TNL-39747-12 (Re), 2013 CanLII 10834 (ON LTB)                TNL-39747-12  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all 44k cases here\n",
    "# all_cases = pd.read_csv(\"/Users/kmaurinjones/Desktop/School/UBC/UBC_Coursework/capstone/Allard_A_Capstone/large_files/44k_cases_pproc_filenums.csv\")\n",
    "all_cases = read_csv_with_lists(\"/Users/kmaurinjones/Desktop/School/UBC/UBC_Coursework/capstone/Allard_A_Capstone/large_files/44k_cases_pproc_filenums.csv\")\n",
    "all_cases.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9968419607304683\n",
      "43698\n",
      "138\n",
      "[55, 101, 102, 196, 352, 357, 480, 502, 518, 616, 791, 908, 928, 1002, 1010, 1014, 1105, 1210, 1271, 1345, 1383, 1428, 4760, 5813, 6561, 7015, 7302, 7488, 7957, 8010, 8132, 8259, 8445, 8698, 8714, 8807, 8913, 9409, 9735, 9775, 10048, 10062, 10104, 10118, 10150, 10372, 10380, 10389, 10414, 10565, 10683, 10777, 10814, 10818, 10853, 10884, 10894, 10955, 11000, 11122, 11177, 11370, 11577, 12806, 14331, 14423, 14472, 14548, 14562, 14695, 14995, 15084, 15292, 15305, 15346, 15469, 15496, 15572, 15588, 15690, 15714, 15779, 16025, 16269, 17547, 17729, 18444, 18627, 18787, 19031, 19467, 19560, 19981, 19984, 20291, 21941, 22065, 22668, 25532, 25919, 26420, 26538, 26962, 27910, 28101, 28572, 29065, 29123, 29688, 30054, 30135, 31009, 31257, 31300, 31866, 32330, 33326, 34362, 35307, 36007, 36875, 36972, 37002, 37409, 37670, 37698, 38370, 38903, 40527, 40598, 40669, 40843, 40997, 41146, 41361, 41811, 42131, 42405]\n",
      "\n",
      "60.7397842056933\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "total_found = 0\n",
    "not_found = []\n",
    "oc_lens = []\n",
    "\n",
    "for row in all_cases.index: # 106 throws indexerror\n",
    "    # print(row)\n",
    "\n",
    "    # row = 108\n",
    "    content_str = \" \".join(all_cases.loc[row, 'content'])\n",
    "    # content_str = \" \".join(content_list) # only if the content is a list\n",
    "    # print(gold_df['new_case_outcome'].tolist()[row])\n",
    "    \n",
    "    # try:\n",
    "        \n",
    "    oc_statement = get_outcome_span(content_str)\n",
    "    # print(oc_statement)\n",
    "    if oc_statement:\n",
    "        total_found += 1\n",
    "        oc_lens.append(len(oc_statement.split()))\n",
    "    else:\n",
    "        not_found.append(row)\n",
    "\n",
    "    # except Exception:\n",
    "    #     not_found.append(row) # error analysis\n",
    "\n",
    "print(total_found / len(all_cases.index))\n",
    "print(len(all_cases))\n",
    "print(len(not_found))\n",
    "print(not_found)\n",
    "print()\n",
    "print(sum(oc_lens) / len(oc_lens)) # average of 61 words per extracted outcome span\n",
    "print(sorted(oc_lens)[len(oc_lens) // 2]) # median of 60 words per extracted outcome span"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis -- Longformer next?\n",
    "- Could probably use Longformer for the cases where the span can't be extracted using the rule-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2878\n",
      "300.32608695652175\n",
      "179\n"
     ]
    }
   ],
   "source": [
    "row = 105\n",
    "total_len = []\n",
    "for row in not_found:\n",
    "\n",
    "    content_str = \" \".join(all_cases.loc[row, 'content'])\n",
    "    \n",
    "    # metadata = \" \".join(all_cases.loc[row, 'metadata'])\n",
    "    # print((row, re.findall(r'<(.*?)>', metadata)[0])) # url\n",
    "\n",
    "    # print(len(get_outcome_span(content_str).split()))\n",
    "    # print(len(content_str.split())) # number of words in the case file\n",
    "    total_len.append(len(content_str.split()))\n",
    "    # print(get_outcome_span(content_str))\n",
    "    # break\n",
    "\n",
    "print()\n",
    "print(max(total_len)) # average number of words in a case file that doesn't have an outcome statement\n",
    "print(sum(total_len) / len(not_found)) # average number of words in a case file that doesn't have an outcome statement\n",
    "print(sorted(total_len)[len(total_len) // 2]) # median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_len.index(max(total_len))\n",
    "# not_found[66]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
